{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HExLQrE4ZxR"
   },
   "source": [
    "<h1><font color='blue'> 8E and 8F: Finding the Probability P(Y==1|X)</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LuKrFzC4ZxV"
   },
   "source": [
    "<h2><font color='Geen'> 8E: Implementing Decision Function of SVM RBF Kernel</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wES-wWN4ZxX"
   },
   "source": [
    "<font face=' Comic Sans MS' size=3>After we train a kernel SVM model, we will be getting support vectors and their corresponsing coefficients $\\alpha_{i}$\n",
    "\n",
    "Check the documentation for better understanding of these attributes: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "<img src='https://i.imgur.com/K11msU4.png' width=500>\n",
    "\n",
    "As a part of this assignment you will be implementing the ```decision_function()``` of kernel SVM, here decision_function() means based on the value return by ```decision_function()``` model will classify the data point either as positive or negative\n",
    "\n",
    "Ex 1: In logistic regression After traning the models with the optimal weights $w$ we get, we will find the value $\\frac{1}{1+\\exp(-(wx+b))}$, if this value comes out to be < 0.5 we will mark it as negative class, else its positive class\n",
    "\n",
    "Ex 2: In Linear SVM After traning the models with the optimal weights $w$ we get, we will find the value of $sign(wx+b)$, if this value comes out to be -ve we will mark it as negative class, else its positive class.\n",
    "\n",
    "Similarly in Kernel SVM After traning the models with the coefficients $\\alpha_{i}$ we get, we will find the value of \n",
    "$sign(\\sum_{i=1}^{n}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here $K(x_{i},x_{q})$ is the RBF kernel. If this value comes out to be -ve we will mark $x_{q}$ as negative class, else its positive class.\n",
    "\n",
    "RBF kernel is defined as: $K(x_{i},x_{q})$ = $exp(-\\gamma ||x_{i} - x_{q}||^2)$\n",
    "\n",
    "For better understanding check this link: https://scikit-learn.org/stable/modules/svm.html#svm-mathematical-formulation\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z830CfMk4Zxa"
   },
   "source": [
    "## Task E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuBxHiCQ4Zxc"
   },
   "source": [
    "> 1. Split the data into $X_{train}$(60), $X_{cv}$(20), $X_{test}$(20)\n",
    "\n",
    "> 2. Train $SVC(gamma=0.001, C=100.)$ on the ($X_{train}$, $y_{train}$)\n",
    "\n",
    "> 3. Get the decision boundry values $f_{cv}$ on the $X_{cv}$ data  i.e. ` `$f_{cv}$ ```= decision_function(```$X_{cv}$```)```  <font color='red'>you need to implement this decision_function()</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "fCgMNEvI4Zxf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "ANUNIqCe4Zxn"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=5000, n_features=5, n_redundant=2,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tHie1zqH4Zxt"
   },
   "source": [
    "### Pseudo code\n",
    "\n",
    "clf = SVC(gamma=0.001, C=100.)<br>\n",
    "clf.fit(Xtrain, ytrain)\n",
    "\n",
    "<font color='green'>def</font> <font color='blue'>decision_function</font>(Xcv, ...): #use appropriate parameters <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='green'>for</font> a data point $x_q$ <font color='green'>in</font> Xcv: <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font color='grey'>#write code to implement $(\\sum_{i=1}^{\\text{all the support vectors}}(y_{i}\\alpha_{i}K(x_{i},x_{q})) + intercept)$, here the values $y_i$, $\\alpha_{i}$, and $intercept$ can be obtained from the trained model</font><br>\n",
    "   <font color='green'>return</font> <font color='grey'><i># the decision_function output for all the data points in the Xcv</i></font>\n",
    "    \n",
    "fcv = decision_function(Xcv, ...)  <i># based on your requirement you can pass any other parameters </i>\n",
    "\n",
    "<b>Note</b>: Make sure the values you get as fcv, should be equal to outputs of clf.decision_function(Xcv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "h43kDT3M41u5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n",
      "(1000,)\n",
      "(1000,)\n",
      "[1 0 1 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 1\n",
      " 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1 0 1 0 1 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0\n",
      " 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 1 1 1 1 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0\n",
      " 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0\n",
      " 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1\n",
      " 0 0 0 1 1 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0 1 1\n",
      " 0 1 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 0 0 1 0 1 0 0 0 1 0 1 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 0\n",
      " 0 0 1 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 1 1 0 1 0 0 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 1 1\n",
      " 0 0 1 0 1 1 1 0 1 1 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 1 1 1 1 0 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 1 0 1 0 1\n",
      " 1 0 0 1 0 1 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 1 1 0 1 0 1 1 1 0 1 0 1 0 1 1 0 1\n",
      " 0 0 1 1 0 0 0 1 1 0 1 1 0 0 0 1 0 1 1 0 1 1 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.40, stratify=y)\n",
    "#We have added “stratify” argument to the y component of the original dataset. This will be used by the train_test_split() function to ensure that both the train and test sets have the proportion of examples in each class that is present in the provided “y” array.\n",
    "X_test, X_cv, y_test, y_cv = train_test_split(X_test, y_test, test_size=0.50, stratify=y_test)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_cv.shape)\n",
    "print(y_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.94111946  1.09040672  0.24088828  0.35462416  0.17451009]\n",
      " [ 0.77456228  0.53681841 -0.07712142 -0.07065843  0.68777714]\n",
      " [ 1.09839234  0.97608615  0.22627505  0.33077986  0.1234874 ]\n",
      " ...\n",
      " [ 0.43193587 -1.0606541  -0.00489413 -0.05746555 -0.8752729 ]\n",
      " [ 0.73022495 -0.21280917  0.0734732   0.08176812 -0.40458146]\n",
      " [-0.27705789  1.1982302   0.05529929  0.12728539  0.83574791]]\n",
      "(566, 5)\n",
      "[-1.98179047]\n",
      "566\n",
      "(1, 566)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(gamma=0.001,C=100) \n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "print(clf.support_vectors_)\n",
    "\n",
    "print(clf.support_vectors_.shape)\n",
    "\n",
    "print(clf.intercept_)\n",
    "\n",
    "print(len(clf.support_vectors_))\n",
    "\n",
    "#print(clf.dual_coef_)\n",
    "\n",
    "print(clf.dual_coef_.shape)\n",
    "\n",
    "print(len(clf.dual_coef_))\n",
    "\n",
    "# print(clf.dual_coef_.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yialphai - dual_coef_[0] from sklearn model -Target value of ith support vector\n",
    "#xq  - data point from xcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1.02462994]), array([-1.74937541]), array([1.76846389]), array([1.85924592]), array([1.98390676]), array([-3.34541903]), array([-2.4054189]), array([-1.12904638]), array([-2.06592972]), array([1.21948426]), array([1.63588688]), array([-1.42362121]), array([-2.83033263]), array([-3.61539072]), array([-0.66176593]), array([-3.6749748]), array([-2.86133108]), array([-2.25569573]), array([-2.86591089]), array([1.60579019]), array([-0.48959409]), array([-2.24892278]), array([0.17519626]), array([-2.06979535]), array([-0.43951343]), array([-2.72517315]), array([-3.52297961]), array([-2.99032594]), array([1.92126961]), array([1.47822272]), array([-2.54840132]), array([1.2362392]), array([-0.77992617]), array([1.66533748]), array([-1.70028515]), array([-1.73957519]), array([1.29781848]), array([1.73400943]), array([-1.57717126]), array([-2.59397634]), array([-1.10898757]), array([0.98777318]), array([0.64420644]), array([0.97603677]), array([1.61222262]), array([-2.1970081]), array([1.82425887]), array([-4.09809427]), array([-2.84090601]), array([-3.2415169]), array([-2.16735326]), array([-0.15338047]), array([-3.20238071]), array([-1.7238454]), array([-1.58853039]), array([-2.78374566]), array([-2.58092775]), array([2.44314042]), array([-0.22062429]), array([-0.6924466]), array([2.16648381]), array([-0.01654727]), array([-2.84074975]), array([-1.73303238]), array([-1.58272086]), array([-2.43565099]), array([1.90451876]), array([-0.99108939]), array([-1.55206026]), array([-1.78169645]), array([-3.6136722]), array([-2.60521316]), array([-3.440265]), array([-1.45007186]), array([-3.24251426]), array([-1.40767656]), array([3.48182151]), array([1.73596086]), array([-3.7515998]), array([-1.26643615]), array([-3.4684342]), array([-3.01254529]), array([-4.41319168]), array([-3.01694909]), array([-3.48276614]), array([-3.84192708]), array([-1.00908902]), array([-2.99934687]), array([0.3520414]), array([-3.47229089]), array([1.36831191]), array([1.43618814]), array([-3.24573024]), array([-2.26540824]), array([-2.45701235]), array([-2.66013558]), array([-0.99574224]), array([-1.76824388]), array([-1.44776019]), array([2.16845116]), array([-0.10503168]), array([2.10751302]), array([-1.63240605]), array([2.21080268]), array([-3.30210065]), array([-2.33590832]), array([-2.70112395]), array([-2.093591]), array([-2.43484908]), array([-3.38307285]), array([-4.91184339]), array([1.51462779]), array([-1.24316141]), array([-1.89551465]), array([-2.79882096]), array([-3.30589544]), array([-2.72246488]), array([-1.55661218]), array([-1.78832099]), array([-2.34751925]), array([2.6774014]), array([1.74662667]), array([-2.21002399]), array([1.03048109]), array([-2.649242]), array([-2.306124]), array([0.26489035]), array([-1.14911847]), array([1.3813543]), array([-2.52068955]), array([-1.25286536]), array([-2.42770182]), array([-4.2777367]), array([-2.70008352]), array([-1.34321188]), array([-2.92624122]), array([0.72991042]), array([-4.17437146]), array([-1.79762271]), array([-4.15612519]), array([3.11560914]), array([1.87969064]), array([-3.35408067]), array([0.42676332]), array([2.43508417]), array([-3.19476024]), array([-1.99967493]), array([-2.50124995]), array([1.83677939]), array([-2.91824827]), array([-2.25885717]), array([-2.83530287]), array([1.82434896]), array([-1.48307134]), array([-0.25901757]), array([1.5524521]), array([-1.67307345]), array([0.22439298]), array([-2.24188632]), array([-1.39416376]), array([-2.24706792]), array([-3.24837747]), array([-3.64657776]), array([-2.64052103]), array([0.60066117]), array([-3.80239031]), array([-1.82350291]), array([-2.72319433]), array([1.91427841]), array([-2.53741037]), array([-3.6193652]), array([-3.85516454]), array([0.49571163]), array([-1.97027692]), array([-2.4528568]), array([2.09263181]), array([1.26316606]), array([-1.09784422]), array([-1.78228931]), array([-2.38342124]), array([-2.66963859]), array([-1.60113127]), array([-3.3494658]), array([1.89979443]), array([-0.6294742]), array([-2.68596029]), array([2.64440643]), array([-3.0171936]), array([-3.48821472]), array([-0.13906771]), array([-1.58827505]), array([-3.62657071]), array([-0.49273021]), array([-1.12872728]), array([-3.11740491]), array([1.42330268]), array([1.09959068]), array([-3.1457805]), array([-2.73908952]), array([-2.33573685]), array([-4.15914303]), array([-0.3480022]), array([2.00621344]), array([-0.60988599]), array([-1.17042186]), array([-3.74777927]), array([1.56829421]), array([2.11420989]), array([-3.73430332]), array([-0.72450373]), array([-3.87298996]), array([-0.94568324]), array([-2.26921797]), array([0.12057313]), array([1.0105706]), array([1.14760706]), array([1.53633554]), array([-1.08567084]), array([-1.47844384]), array([-4.46900056]), array([-2.85526308]), array([-2.04000654]), array([-2.9933124]), array([-3.52809113]), array([-0.82194033]), array([-1.75470455]), array([-3.1385168]), array([-3.26789485]), array([-0.58971607]), array([-1.52255483]), array([-2.74824608]), array([-3.29992606]), array([1.58820481]), array([-0.59603973]), array([-3.71538005]), array([-0.46018514]), array([0.36599824]), array([2.02956977]), array([-2.97033604]), array([1.61503418]), array([-2.25034839]), array([-2.61613]), array([-1.89201446]), array([-1.00006142]), array([-2.16598748]), array([-2.36157473]), array([-1.88812454]), array([-3.40322235]), array([0.24060049]), array([-2.72674736]), array([1.42450394]), array([-0.10338633]), array([-4.13915089]), array([-3.00047403]), array([2.06790682]), array([-2.60192325]), array([1.33453045]), array([-2.24111998]), array([-5.32480686]), array([-0.75774722]), array([-2.74847509]), array([1.70006066]), array([-2.94719088]), array([-3.12375064]), array([-3.42293305]), array([-2.44336797]), array([1.89058937]), array([-1.86797594]), array([1.33181171]), array([-0.78099131]), array([1.58964036]), array([0.80755824]), array([-3.07750247]), array([-3.39181225]), array([-0.82653745]), array([-3.52574288]), array([-2.49445281]), array([0.82108458]), array([-1.94553729]), array([-0.5019174]), array([-3.51227069]), array([-1.63995456]), array([-3.23909236]), array([-4.03118989]), array([-2.13228844]), array([-3.86489625]), array([-1.64409978]), array([-0.66860407]), array([-3.06155389]), array([0.93522311]), array([-2.56399695]), array([-3.16075431]), array([-1.67251746]), array([0.79954394]), array([-1.59818197]), array([-1.86938756]), array([1.88381315]), array([-2.46315349]), array([-2.76875401]), array([-2.438923]), array([-1.24025589]), array([-0.22202957]), array([0.06958761]), array([-4.02229447]), array([-0.26382964]), array([-1.54265287]), array([-2.41639675]), array([1.80845242]), array([1.37606197]), array([-4.85188775]), array([-2.6608779]), array([-3.04345105]), array([1.50394053]), array([-3.70949086]), array([-2.9578838]), array([-3.17550925]), array([-2.20462067]), array([1.76788387]), array([-3.21298521]), array([-2.63515124]), array([-3.63500272]), array([-3.79950876]), array([-0.07123889]), array([-2.79611688]), array([-0.87777495]), array([-2.64251732]), array([-2.08163342]), array([2.36816325]), array([-2.60314338]), array([1.47973503]), array([-2.12942483]), array([-3.00571184]), array([-0.32530075]), array([-2.94445639]), array([1.92893333]), array([-2.53329424]), array([2.02551091]), array([-2.32550051]), array([-1.99835166]), array([-3.08602432]), array([-3.05245616]), array([0.11957697]), array([-3.92670315]), array([1.89601708]), array([1.18317615]), array([-2.1604802]), array([-3.29180627]), array([0.6006226]), array([1.55287731]), array([-0.32122805]), array([-0.80118749]), array([2.95550649]), array([-1.35459127]), array([1.80548411]), array([-2.59595705]), array([-1.51912278]), array([-0.41536289]), array([-4.46551169]), array([1.66223095]), array([-3.57088834]), array([-1.49892652]), array([-3.07595178]), array([1.39484113]), array([-1.52753]), array([0.92710282]), array([-1.77254964]), array([0.87218914]), array([-0.78063846]), array([1.48168129]), array([-3.50259262]), array([-1.99987051]), array([-2.48553084]), array([-0.32217963]), array([-3.33901701]), array([-4.00008218]), array([0.83645969]), array([0.43827511]), array([-0.71064494]), array([-3.08986245]), array([-3.40460632]), array([-3.28011912]), array([-3.11974816]), array([0.36177723]), array([-3.00002431]), array([0.13722432]), array([-3.6511595]), array([-3.07120701]), array([-2.63696436]), array([-2.10294573]), array([-2.78180657]), array([-2.46021056]), array([-1.78850795]), array([0.25250396]), array([-2.72580277]), array([1.25916791]), array([3.69577046]), array([-1.68503388]), array([1.79142771]), array([-3.96237605]), array([-0.14689448]), array([-2.01240353]), array([-1.67698141]), array([-3.69464901]), array([-1.72136705]), array([1.48146174]), array([-3.26532911]), array([-2.31494766]), array([-2.44874683]), array([-2.04089126]), array([-3.66963798]), array([1.90441567]), array([1.73405036]), array([-3.95372026]), array([1.09208319]), array([-2.34519768]), array([-1.0562034]), array([0.72631529]), array([-0.64821362]), array([-1.21348001]), array([0.96772611]), array([-3.1091926]), array([1.73744423]), array([-4.18262419]), array([-0.8240578]), array([-2.5637844]), array([-1.69906647]), array([1.2828356]), array([1.77710972]), array([-3.16522197]), array([1.82924912]), array([-2.37836333]), array([1.74061371]), array([-2.66526156]), array([-2.31371977]), array([-1.42477884]), array([-2.87290826]), array([-0.76978179]), array([1.23635909]), array([1.36124997]), array([2.23496834]), array([-2.72117588]), array([-1.09222405]), array([0.9894785]), array([1.72696511]), array([-1.07952456]), array([-3.67199146]), array([-2.52882093]), array([0.13130367]), array([3.93612249]), array([-2.54339149]), array([0.80947585]), array([-2.66287833]), array([1.17798889]), array([-2.50151138]), array([1.03679728]), array([-3.53726893]), array([-2.4741597]), array([-0.9994783]), array([1.53959123]), array([-4.24548862]), array([-3.03948438]), array([0.19332898]), array([-2.2924955]), array([-3.01523837]), array([-0.95663023]), array([-0.49671666]), array([-1.85183526]), array([-1.96200297]), array([-2.6368224]), array([-3.17438075]), array([-2.91221867]), array([-2.14301834]), array([1.64792106]), array([-3.14234702]), array([-1.70869864]), array([1.81648516]), array([1.59439992]), array([-1.63119994]), array([2.11824]), array([-3.11283951]), array([-4.02911566]), array([-3.43522976]), array([-3.71022893]), array([-3.59370365]), array([-2.66133156]), array([-3.65195972]), array([-3.72596087]), array([-3.86901747]), array([-2.59334581]), array([-3.59229665]), array([-1.85379262]), array([-4.44841483]), array([-2.94947831]), array([-4.18376702]), array([-2.88322757]), array([-3.22782691]), array([0.93895496]), array([1.97146066]), array([-3.15757284]), array([-1.71391975]), array([-1.15347862]), array([-2.98763401]), array([-3.83606587]), array([-2.79941865]), array([0.94030719]), array([-2.62176005]), array([1.54902428]), array([-2.65237965]), array([-3.34420828]), array([-3.60635271]), array([-4.85826266]), array([-3.36198664]), array([-4.75754344]), array([-1.40948892]), array([-2.64884878]), array([-4.47319677]), array([-0.62740361]), array([-4.74939251]), array([-0.18632742]), array([-2.65765713]), array([-3.73000758]), array([-3.32887424]), array([2.47633496]), array([-3.75721365]), array([-2.94165081]), array([-0.32258286]), array([-3.92868067]), array([-2.10224999]), array([1.20823679]), array([0.56261814]), array([-2.43252867]), array([-3.84316242]), array([-3.64990814]), array([-1.35359159]), array([-1.01015772]), array([-1.78043815]), array([-3.66005001]), array([-2.60764349]), array([-2.26591522]), array([0.06569787]), array([0.62570521]), array([-3.41923798]), array([1.41322216]), array([1.5024162]), array([-3.23656458]), array([-3.39774098]), array([-2.62631026]), array([0.73465496]), array([0.12404803]), array([-1.46834711]), array([-0.95583514]), array([-3.47728013]), array([-3.02873207]), array([-1.14602871]), array([-0.93726575]), array([-2.3685192]), array([1.24709702]), array([-2.69593205]), array([-0.4274252]), array([2.90921454]), array([-3.67847304]), array([-3.78868248]), array([-4.04261115]), array([-0.54452905]), array([1.3150532]), array([-4.17982703]), array([-2.97890203]), array([-1.55149789]), array([-2.84080611]), array([-2.8505612]), array([-4.23344861]), array([-4.18963103]), array([1.04686069]), array([1.77084485]), array([-3.13338463]), array([-1.16330244]), array([-2.74735014]), array([-3.51114708]), array([-3.6095939]), array([2.05225248]), array([-2.85905501]), array([-1.53475661]), array([-3.12895771]), array([0.00431984]), array([-3.69411834]), array([-1.41595673]), array([2.75464548]), array([-1.84920603]), array([-2.7292252]), array([-3.34457114]), array([1.83245168]), array([-1.98001115]), array([-3.60458513]), array([1.61340581]), array([-2.21703596]), array([-1.78794717]), array([-4.37481795]), array([-2.3272536]), array([-3.0414489]), array([-3.10215173]), array([2.4103186]), array([-2.23208941]), array([1.77721933]), array([-2.24456213]), array([-1.82406055]), array([-2.36729939]), array([2.18512575]), array([-2.93059947]), array([3.30311225]), array([1.76239096]), array([1.65665938]), array([-0.03102021]), array([-2.90232001]), array([-1.73127648]), array([-4.38641163]), array([1.45246674]), array([-2.43926312]), array([-1.71248148]), array([-1.45025584]), array([-3.19516129]), array([-3.91013524]), array([-1.17974007]), array([-0.89651922]), array([-2.81806769]), array([-4.19566571]), array([-2.01937328]), array([2.04127534]), array([-0.1979484]), array([-0.45889709]), array([-1.90425546]), array([-2.34990743]), array([-1.73907612]), array([-3.28212846]), array([1.67862681]), array([-2.7934201]), array([1.81425439]), array([-4.76886639]), array([-1.46658581]), array([-2.56712419]), array([1.25583246]), array([-3.99400322]), array([1.05763332]), array([-2.68774195]), array([1.84141021]), array([-1.42550771]), array([-1.84564527]), array([2.53504315]), array([2.23055285]), array([-0.16809481]), array([0.09410109]), array([-2.10716318]), array([-1.38431564]), array([-2.13199403]), array([-2.61142555]), array([1.56967795]), array([2.43772731]), array([-2.00482238]), array([-1.49258198]), array([-1.67310088]), array([1.56293561]), array([-4.01178651]), array([-2.03913485]), array([-0.73650165]), array([1.40561146]), array([-2.47316303]), array([-0.86721873]), array([-2.55334535]), array([-2.83779294]), array([2.4138196]), array([2.07642746]), array([-4.74847146]), array([-3.25034405]), array([2.61524202]), array([-1.45721271]), array([-1.84651833]), array([-3.68857269]), array([-0.37013096]), array([2.49462469]), array([-2.49793488]), array([-2.3922215]), array([1.70781065]), array([-3.1826803]), array([-2.48217869]), array([-2.43642541]), array([1.88423727]), array([-2.77441722]), array([-0.77532679]), array([-3.08656004]), array([-4.07168734]), array([-3.00802618]), array([-3.25873348]), array([2.78511991]), array([1.42856674]), array([2.48781991]), array([-2.38061362]), array([-2.73299729]), array([-3.0568174]), array([-0.69425277]), array([-1.95875381]), array([-3.18039988]), array([-1.70687077]), array([-2.96595693]), array([-2.72559672]), array([0.92637181]), array([-2.58116225]), array([-1.20196193]), array([-2.27035395]), array([-2.50482805]), array([1.01102959]), array([-1.11059794]), array([-1.90422202]), array([1.77958182]), array([1.83106095]), array([-3.48054115]), array([-2.20552162]), array([-1.31926178]), array([-1.7307557]), array([-3.44047887]), array([-3.07803478]), array([2.318134]), array([-2.96092503]), array([-1.78137281]), array([1.17774714]), array([2.58692188]), array([-0.41043933]), array([-2.87906024]), array([-0.39372581]), array([1.63866299]), array([-2.58118655]), array([-1.13259919]), array([-3.01465567]), array([-4.26940488]), array([1.53415563]), array([-1.52896231]), array([-1.40341669]), array([-1.98665538]), array([-2.02089371]), array([0.09868271]), array([-3.09397261]), array([-1.82557044]), array([1.51965292]), array([1.661716]), array([-1.4696588]), array([-0.51896786]), array([-3.61596796]), array([-3.21189165]), array([-2.10387095]), array([1.43857679]), array([1.62739013]), array([-4.37871781]), array([0.19134064]), array([1.26680643]), array([-3.15886486]), array([-2.88702786]), array([0.71475007]), array([-2.19989847]), array([-3.92742773]), array([-0.90944799]), array([-2.21258187]), array([-2.26502456]), array([-1.52053679]), array([-1.01478211]), array([1.25801163]), array([-2.96050385]), array([-4.90491887]), array([-1.51208706]), array([-2.89498198]), array([-1.60475694]), array([1.29067029]), array([-2.12533331]), array([-2.35871399]), array([-2.69289706]), array([-1.77392658]), array([1.69838135]), array([1.7678887]), array([-4.60569056]), array([-1.05476736]), array([-1.53684553]), array([-2.03019558]), array([-0.16448978]), array([-2.65368819]), array([-2.90844466]), array([-2.36132561]), array([-1.95908502]), array([-1.36741031]), array([1.1775241]), array([-3.04583084]), array([-2.85564007]), array([1.88595818]), array([-2.86035311]), array([-2.72738337]), array([1.94012171]), array([-2.29805101]), array([-3.41110217]), array([-3.62346618]), array([0.3135429]), array([0.82310377]), array([-0.41040335]), array([-2.39437271]), array([-0.73113172]), array([-2.92960323]), array([2.61155373]), array([-2.71611071]), array([-2.40631966]), array([-2.95551874]), array([0.75341024]), array([-1.80541362]), array([-1.37522883]), array([-2.23745242]), array([-3.39507435]), array([2.06498244]), array([-2.82423349]), array([2.4770017]), array([1.64900381]), array([-1.44036969]), array([-3.17424198]), array([-3.59765676]), array([-2.23823411]), array([1.38091236]), array([1.31759198]), array([0.13485078]), array([-2.35042664]), array([1.85473416]), array([0.11226179]), array([0.54259524]), array([0.61091151]), array([0.85748624]), array([0.62114778]), array([1.67975003]), array([-1.41523194]), array([-1.81379022]), array([-2.30174565]), array([1.81920698]), array([-2.20370315]), array([-0.83184572]), array([-3.24128863]), array([-1.87457795]), array([-1.24403884]), array([-2.81380017]), array([-3.38627877]), array([-4.02875022]), array([-2.74003448]), array([-0.26138689]), array([-2.02535399]), array([1.79592785]), array([-1.78750509]), array([-2.03293487]), array([-2.58335765]), array([2.43856845]), array([1.72931083]), array([-3.48168187]), array([-2.30133757]), array([-2.67277674]), array([-3.58065901]), array([-2.03343545]), array([-1.81476396]), array([-2.33591967]), array([-0.11450536]), array([-0.58642607]), array([-1.25973285]), array([1.80406795]), array([-1.78882331]), array([-2.12282046]), array([-2.04849939]), array([1.62193951]), array([-0.18520973]), array([-1.50150616]), array([-2.16605433]), array([-2.04298214]), array([-1.98180406]), array([-3.99286717]), array([-2.24793763]), array([0.85896906]), array([-2.43235845]), array([-2.10095573]), array([0.86676]), array([-2.74911925]), array([-2.86545916]), array([2.07936751]), array([0.65437304]), array([-0.73631605]), array([-3.27385084]), array([-3.58988205]), array([2.01757408]), array([-2.12557363]), array([0.9685527]), array([-2.65499444]), array([2.22860484]), array([2.44336089]), array([-2.2482022]), array([-4.59459709]), array([0.75744372]), array([-2.91941278]), array([2.02593838]), array([-1.35993871]), array([-3.94047257]), array([-2.22844436]), array([1.60827341]), array([-1.75138726]), array([-3.41221752]), array([-2.506898]), array([1.00034178]), array([-2.50886977]), array([-2.75404893]), array([-3.04817202]), array([-2.29967595]), array([1.97985466]), array([1.21461806]), array([-4.02004367]), array([1.65427913]), array([1.24677687]), array([1.89015853]), array([-3.09620975]), array([-2.7886401]), array([-0.7459617]), array([-2.77357339]), array([-2.73471072]), array([1.4141921]), array([1.13262039]), array([-0.23131753]), array([-1.47954075]), array([-2.88898679]), array([-2.87020692]), array([-2.27433515]), array([-2.18705675]), array([-1.837322]), array([1.58102181]), array([-2.50230494]), array([1.5508406]), array([-0.46272768]), array([0.11963865]), array([-0.67528496]), array([-3.56749402]), array([-1.2827595]), array([-3.21725131]), array([0.90524819]), array([-1.95110377]), array([3.3731943]), array([0.30249799]), array([-1.37157329]), array([-2.15993362]), array([-3.5291312]), array([-1.06380489]), array([-3.12668822]), array([1.58068969]), array([-0.15938455]), array([1.9360087]), array([-2.39119973]), array([3.32415438]), array([0.4931687]), array([1.69273902]), array([2.20882318]), array([1.27088244]), array([-0.6929288]), array([1.71038393]), array([-1.21186645]), array([1.85694554]), array([-2.90178235]), array([-0.72905856]), array([0.97237626]), array([-2.48114418]), array([-2.77962773]), array([-2.33942248]), array([-3.24854692]), array([1.33448213]), array([2.05917016]), array([-4.04217396]), array([-3.87710805]), array([-2.88179775]), array([2.41971444]), array([1.18613036]), array([-2.49845928]), array([2.11902071]), array([1.7033715]), array([-2.22627202]), array([-2.30634193]), array([-1.92896499]), array([1.16772902]), array([-1.47444767]), array([1.21841775]), array([1.28553535]), array([-2.80088664]), array([1.62542587]), array([0.05639389]), array([-3.04918365]), array([-2.73605678]), array([-1.9149303]), array([0.33949587]), array([0.24286502]), array([1.45530689]), array([-0.29022309]), array([-1.5720803]), array([-2.25864259]), array([-2.07376093]), array([-3.59142914]), array([-2.47432398]), array([-4.50228397]), array([-3.05709416]), array([0.8145741]), array([-1.30174633])]\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "from numpy import linalg\n",
    "yialphai = clf.dual_coef_\n",
    "support_vectors = clf.support_vectors_\n",
    "intercept = clf.intercept_\n",
    "\n",
    "gamma = 0.001\n",
    "\n",
    "def decision_boundary(X_cv,yialphai,support_vectors,intercept):\n",
    "    y_pred = []\n",
    "    for p in X_cv:\n",
    "        sum =0   \n",
    "        final_value = 0\n",
    "        for i in range(len(support_vectors)):\n",
    "            norm = np.linalg.norm((support_vectors[i]-p))\n",
    "            pow = np.exp(-gamma*(norm**2))\n",
    "            sum +=yialphai[0][i]*pow\n",
    "            final_value = sum+intercept\n",
    "        y_pred.append(final_value)\n",
    "    return y_pred\n",
    "\n",
    "fcv = decision_boundary(X_cv,yialphai,support_vectors,intercept)\n",
    "ftest = decision_boundary(X_test,yialphai,support_vectors,intercept)\n",
    "print(fcv)\n",
    "print(len(fcv))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.02462994e+00 -1.74937541e+00  1.76846389e+00  1.85924592e+00\n",
      "  1.98390676e+00 -3.34541903e+00 -2.40541890e+00 -1.12904638e+00\n",
      " -2.06592972e+00  1.21948426e+00  1.63588688e+00 -1.42362121e+00\n",
      " -2.83033263e+00 -3.61539072e+00 -6.61765932e-01 -3.67497480e+00\n",
      " -2.86133108e+00 -2.25569573e+00 -2.86591089e+00  1.60579019e+00\n",
      " -4.89594091e-01 -2.24892278e+00  1.75196261e-01 -2.06979535e+00\n",
      " -4.39513426e-01 -2.72517315e+00 -3.52297961e+00 -2.99032594e+00\n",
      "  1.92126961e+00  1.47822272e+00 -2.54840132e+00  1.23623920e+00\n",
      " -7.79926166e-01  1.66533748e+00 -1.70028515e+00 -1.73957519e+00\n",
      "  1.29781848e+00  1.73400943e+00 -1.57717126e+00 -2.59397634e+00\n",
      " -1.10898757e+00  9.87773183e-01  6.44206438e-01  9.76036771e-01\n",
      "  1.61222262e+00 -2.19700810e+00  1.82425887e+00 -4.09809427e+00\n",
      " -2.84090601e+00 -3.24151690e+00 -2.16735326e+00 -1.53380470e-01\n",
      " -3.20238071e+00 -1.72384540e+00 -1.58853039e+00 -2.78374566e+00\n",
      " -2.58092775e+00  2.44314042e+00 -2.20624286e-01 -6.92446597e-01\n",
      "  2.16648381e+00 -1.65472712e-02 -2.84074975e+00 -1.73303238e+00\n",
      " -1.58272086e+00 -2.43565099e+00  1.90451876e+00 -9.91089391e-01\n",
      " -1.55206026e+00 -1.78169645e+00 -3.61367220e+00 -2.60521316e+00\n",
      " -3.44026500e+00 -1.45007186e+00 -3.24251426e+00 -1.40767656e+00\n",
      "  3.48182151e+00  1.73596086e+00 -3.75159980e+00 -1.26643615e+00\n",
      " -3.46843420e+00 -3.01254529e+00 -4.41319168e+00 -3.01694909e+00\n",
      " -3.48276614e+00 -3.84192708e+00 -1.00908902e+00 -2.99934687e+00\n",
      "  3.52041398e-01 -3.47229089e+00  1.36831191e+00  1.43618814e+00\n",
      " -3.24573024e+00 -2.26540824e+00 -2.45701235e+00 -2.66013558e+00\n",
      " -9.95742239e-01 -1.76824388e+00 -1.44776019e+00  2.16845116e+00\n",
      " -1.05031677e-01  2.10751302e+00 -1.63240605e+00  2.21080268e+00\n",
      " -3.30210065e+00 -2.33590832e+00 -2.70112395e+00 -2.09359100e+00\n",
      " -2.43484908e+00 -3.38307285e+00 -4.91184339e+00  1.51462779e+00\n",
      " -1.24316141e+00 -1.89551465e+00 -2.79882096e+00 -3.30589544e+00\n",
      " -2.72246488e+00 -1.55661218e+00 -1.78832099e+00 -2.34751925e+00\n",
      "  2.67740140e+00  1.74662667e+00 -2.21002399e+00  1.03048109e+00\n",
      " -2.64924200e+00 -2.30612400e+00  2.64890348e-01 -1.14911847e+00\n",
      "  1.38135430e+00 -2.52068955e+00 -1.25286536e+00 -2.42770182e+00\n",
      " -4.27773670e+00 -2.70008352e+00 -1.34321188e+00 -2.92624122e+00\n",
      "  7.29910416e-01 -4.17437146e+00 -1.79762271e+00 -4.15612519e+00\n",
      "  3.11560914e+00  1.87969064e+00 -3.35408067e+00  4.26763316e-01\n",
      "  2.43508417e+00 -3.19476024e+00 -1.99967493e+00 -2.50124995e+00\n",
      "  1.83677939e+00 -2.91824827e+00 -2.25885717e+00 -2.83530287e+00\n",
      "  1.82434896e+00 -1.48307134e+00 -2.59017571e-01  1.55245210e+00\n",
      " -1.67307345e+00  2.24392982e-01 -2.24188632e+00 -1.39416376e+00\n",
      " -2.24706792e+00 -3.24837747e+00 -3.64657776e+00 -2.64052103e+00\n",
      "  6.00661166e-01 -3.80239031e+00 -1.82350291e+00 -2.72319433e+00\n",
      "  1.91427841e+00 -2.53741037e+00 -3.61936520e+00 -3.85516454e+00\n",
      "  4.95711632e-01 -1.97027692e+00 -2.45285680e+00  2.09263181e+00\n",
      "  1.26316606e+00 -1.09784422e+00 -1.78228931e+00 -2.38342124e+00\n",
      " -2.66963859e+00 -1.60113127e+00 -3.34946580e+00  1.89979443e+00\n",
      " -6.29474202e-01 -2.68596029e+00  2.64440643e+00 -3.01719360e+00\n",
      " -3.48821472e+00 -1.39067708e-01 -1.58827505e+00 -3.62657071e+00\n",
      " -4.92730215e-01 -1.12872728e+00 -3.11740491e+00  1.42330268e+00\n",
      "  1.09959068e+00 -3.14578050e+00 -2.73908952e+00 -2.33573685e+00\n",
      " -4.15914303e+00 -3.48002203e-01  2.00621344e+00 -6.09885994e-01\n",
      " -1.17042186e+00 -3.74777927e+00  1.56829421e+00  2.11420989e+00\n",
      " -3.73430332e+00 -7.24503727e-01 -3.87298996e+00 -9.45683242e-01\n",
      " -2.26921797e+00  1.20573133e-01  1.01057060e+00  1.14760706e+00\n",
      "  1.53633554e+00 -1.08567084e+00 -1.47844384e+00 -4.46900056e+00\n",
      " -2.85526308e+00 -2.04000654e+00 -2.99331240e+00 -3.52809113e+00\n",
      " -8.21940327e-01 -1.75470455e+00 -3.13851680e+00 -3.26789485e+00\n",
      " -5.89716071e-01 -1.52255483e+00 -2.74824608e+00 -3.29992606e+00\n",
      "  1.58820481e+00 -5.96039734e-01 -3.71538005e+00 -4.60185137e-01\n",
      "  3.65998244e-01  2.02956977e+00 -2.97033604e+00  1.61503418e+00\n",
      " -2.25034839e+00 -2.61613000e+00 -1.89201446e+00 -1.00006142e+00\n",
      " -2.16598748e+00 -2.36157473e+00 -1.88812454e+00 -3.40322235e+00\n",
      "  2.40600494e-01 -2.72674736e+00  1.42450394e+00 -1.03386334e-01\n",
      " -4.13915089e+00 -3.00047403e+00  2.06790682e+00 -2.60192325e+00\n",
      "  1.33453045e+00 -2.24111998e+00 -5.32480686e+00 -7.57747216e-01\n",
      " -2.74847509e+00  1.70006066e+00 -2.94719088e+00 -3.12375064e+00\n",
      " -3.42293305e+00 -2.44336797e+00  1.89058937e+00 -1.86797594e+00\n",
      "  1.33181171e+00 -7.80991315e-01  1.58964036e+00  8.07558239e-01\n",
      " -3.07750247e+00 -3.39181225e+00 -8.26537450e-01 -3.52574288e+00\n",
      " -2.49445281e+00  8.21084579e-01 -1.94553729e+00 -5.01917397e-01\n",
      " -3.51227069e+00 -1.63995456e+00 -3.23909236e+00 -4.03118989e+00\n",
      " -2.13228844e+00 -3.86489625e+00 -1.64409978e+00 -6.68604065e-01\n",
      " -3.06155389e+00  9.35223110e-01 -2.56399695e+00 -3.16075431e+00\n",
      " -1.67251746e+00  7.99543936e-01 -1.59818197e+00 -1.86938756e+00\n",
      "  1.88381315e+00 -2.46315349e+00 -2.76875401e+00 -2.43892300e+00\n",
      " -1.24025589e+00 -2.22029570e-01  6.95876144e-02 -4.02229447e+00\n",
      " -2.63829639e-01 -1.54265287e+00 -2.41639675e+00  1.80845242e+00\n",
      "  1.37606197e+00 -4.85188775e+00 -2.66087790e+00 -3.04345105e+00\n",
      "  1.50394053e+00 -3.70949086e+00 -2.95788380e+00 -3.17550925e+00\n",
      " -2.20462067e+00  1.76788387e+00 -3.21298521e+00 -2.63515124e+00\n",
      " -3.63500272e+00 -3.79950876e+00 -7.12388896e-02 -2.79611688e+00\n",
      " -8.77774952e-01 -2.64251732e+00 -2.08163342e+00  2.36816325e+00\n",
      " -2.60314338e+00  1.47973503e+00 -2.12942483e+00 -3.00571184e+00\n",
      " -3.25300750e-01 -2.94445639e+00  1.92893333e+00 -2.53329424e+00\n",
      "  2.02551091e+00 -2.32550051e+00 -1.99835166e+00 -3.08602432e+00\n",
      " -3.05245616e+00  1.19576966e-01 -3.92670315e+00  1.89601708e+00\n",
      "  1.18317615e+00 -2.16048020e+00 -3.29180627e+00  6.00622602e-01\n",
      "  1.55287731e+00 -3.21228055e-01 -8.01187490e-01  2.95550649e+00\n",
      " -1.35459127e+00  1.80548411e+00 -2.59595705e+00 -1.51912278e+00\n",
      " -4.15362893e-01 -4.46551169e+00  1.66223095e+00 -3.57088834e+00\n",
      " -1.49892652e+00 -3.07595178e+00  1.39484113e+00 -1.52753000e+00\n",
      "  9.27102823e-01 -1.77254964e+00  8.72189143e-01 -7.80638460e-01\n",
      "  1.48168129e+00 -3.50259262e+00 -1.99987051e+00 -2.48553084e+00\n",
      " -3.22179634e-01 -3.33901701e+00 -4.00008218e+00  8.36459687e-01\n",
      "  4.38275113e-01 -7.10644944e-01 -3.08986245e+00 -3.40460632e+00\n",
      " -3.28011912e+00 -3.11974816e+00  3.61777231e-01 -3.00002431e+00\n",
      "  1.37224320e-01 -3.65115950e+00 -3.07120701e+00 -2.63696436e+00\n",
      " -2.10294573e+00 -2.78180657e+00 -2.46021056e+00 -1.78850795e+00\n",
      "  2.52503963e-01 -2.72580277e+00  1.25916791e+00  3.69577046e+00\n",
      " -1.68503388e+00  1.79142771e+00 -3.96237605e+00 -1.46894482e-01\n",
      " -2.01240353e+00 -1.67698141e+00 -3.69464901e+00 -1.72136705e+00\n",
      "  1.48146174e+00 -3.26532911e+00 -2.31494766e+00 -2.44874683e+00\n",
      " -2.04089126e+00 -3.66963798e+00  1.90441567e+00  1.73405036e+00\n",
      " -3.95372026e+00  1.09208319e+00 -2.34519768e+00 -1.05620340e+00\n",
      "  7.26315293e-01 -6.48213621e-01 -1.21348001e+00  9.67726114e-01\n",
      " -3.10919260e+00  1.73744423e+00 -4.18262419e+00 -8.24057801e-01\n",
      " -2.56378440e+00 -1.69906647e+00  1.28283560e+00  1.77710972e+00\n",
      " -3.16522197e+00  1.82924912e+00 -2.37836333e+00  1.74061371e+00\n",
      " -2.66526156e+00 -2.31371977e+00 -1.42477884e+00 -2.87290826e+00\n",
      " -7.69781791e-01  1.23635909e+00  1.36124997e+00  2.23496834e+00\n",
      " -2.72117588e+00 -1.09222405e+00  9.89478496e-01  1.72696511e+00\n",
      " -1.07952456e+00 -3.67199146e+00 -2.52882093e+00  1.31303672e-01\n",
      "  3.93612249e+00 -2.54339149e+00  8.09475849e-01 -2.66287833e+00\n",
      "  1.17798889e+00 -2.50151138e+00  1.03679728e+00 -3.53726893e+00\n",
      " -2.47415970e+00 -9.99478301e-01  1.53959123e+00 -4.24548862e+00\n",
      " -3.03948438e+00  1.93328984e-01 -2.29249550e+00 -3.01523837e+00\n",
      " -9.56630227e-01 -4.96716656e-01 -1.85183526e+00 -1.96200297e+00\n",
      " -2.63682240e+00 -3.17438075e+00 -2.91221867e+00 -2.14301834e+00\n",
      "  1.64792106e+00 -3.14234702e+00 -1.70869864e+00  1.81648516e+00\n",
      "  1.59439992e+00 -1.63119994e+00  2.11824000e+00 -3.11283951e+00\n",
      " -4.02911566e+00 -3.43522976e+00 -3.71022893e+00 -3.59370365e+00\n",
      " -2.66133156e+00 -3.65195972e+00 -3.72596087e+00 -3.86901747e+00\n",
      " -2.59334581e+00 -3.59229665e+00 -1.85379262e+00 -4.44841483e+00\n",
      " -2.94947831e+00 -4.18376702e+00 -2.88322757e+00 -3.22782691e+00\n",
      "  9.38954960e-01  1.97146066e+00 -3.15757284e+00 -1.71391975e+00\n",
      " -1.15347862e+00 -2.98763401e+00 -3.83606587e+00 -2.79941865e+00\n",
      "  9.40307186e-01 -2.62176005e+00  1.54902428e+00 -2.65237965e+00\n",
      " -3.34420828e+00 -3.60635271e+00 -4.85826266e+00 -3.36198664e+00\n",
      " -4.75754344e+00 -1.40948892e+00 -2.64884878e+00 -4.47319677e+00\n",
      " -6.27403613e-01 -4.74939251e+00 -1.86327416e-01 -2.65765713e+00\n",
      " -3.73000758e+00 -3.32887424e+00  2.47633496e+00 -3.75721365e+00\n",
      " -2.94165081e+00 -3.22582859e-01 -3.92868067e+00 -2.10224999e+00\n",
      "  1.20823679e+00  5.62618137e-01 -2.43252867e+00 -3.84316242e+00\n",
      " -3.64990814e+00 -1.35359159e+00 -1.01015772e+00 -1.78043815e+00\n",
      " -3.66005001e+00 -2.60764349e+00 -2.26591522e+00  6.56978651e-02\n",
      "  6.25705215e-01 -3.41923798e+00  1.41322216e+00  1.50241620e+00\n",
      " -3.23656458e+00 -3.39774098e+00 -2.62631026e+00  7.34654964e-01\n",
      "  1.24048032e-01 -1.46834711e+00 -9.55835137e-01 -3.47728013e+00\n",
      " -3.02873207e+00 -1.14602871e+00 -9.37265750e-01 -2.36851920e+00\n",
      "  1.24709702e+00 -2.69593205e+00 -4.27425202e-01  2.90921454e+00\n",
      " -3.67847304e+00 -3.78868248e+00 -4.04261115e+00 -5.44529050e-01\n",
      "  1.31505320e+00 -4.17982703e+00 -2.97890203e+00 -1.55149789e+00\n",
      " -2.84080611e+00 -2.85056120e+00 -4.23344861e+00 -4.18963103e+00\n",
      "  1.04686069e+00  1.77084485e+00 -3.13338463e+00 -1.16330244e+00\n",
      " -2.74735014e+00 -3.51114708e+00 -3.60959390e+00  2.05225248e+00\n",
      " -2.85905501e+00 -1.53475661e+00 -3.12895771e+00  4.31984481e-03\n",
      " -3.69411834e+00 -1.41595673e+00  2.75464548e+00 -1.84920603e+00\n",
      " -2.72922520e+00 -3.34457114e+00  1.83245168e+00 -1.98001115e+00\n",
      " -3.60458513e+00  1.61340581e+00 -2.21703596e+00 -1.78794717e+00\n",
      " -4.37481795e+00 -2.32725360e+00 -3.04144890e+00 -3.10215173e+00\n",
      "  2.41031860e+00 -2.23208941e+00  1.77721933e+00 -2.24456213e+00\n",
      " -1.82406055e+00 -2.36729939e+00  2.18512575e+00 -2.93059947e+00\n",
      "  3.30311225e+00  1.76239096e+00  1.65665938e+00 -3.10202072e-02\n",
      " -2.90232001e+00 -1.73127648e+00 -4.38641163e+00  1.45246674e+00\n",
      " -2.43926312e+00 -1.71248148e+00 -1.45025584e+00 -3.19516129e+00\n",
      " -3.91013524e+00 -1.17974007e+00 -8.96519221e-01 -2.81806769e+00\n",
      " -4.19566571e+00 -2.01937328e+00  2.04127534e+00 -1.97948397e-01\n",
      " -4.58897092e-01 -1.90425546e+00 -2.34990743e+00 -1.73907612e+00\n",
      " -3.28212846e+00  1.67862681e+00 -2.79342010e+00  1.81425439e+00\n",
      " -4.76886639e+00 -1.46658581e+00 -2.56712419e+00  1.25583246e+00\n",
      " -3.99400322e+00  1.05763332e+00 -2.68774195e+00  1.84141021e+00\n",
      " -1.42550771e+00 -1.84564527e+00  2.53504315e+00  2.23055285e+00\n",
      " -1.68094812e-01  9.41010888e-02 -2.10716318e+00 -1.38431564e+00\n",
      " -2.13199403e+00 -2.61142555e+00  1.56967795e+00  2.43772731e+00\n",
      " -2.00482238e+00 -1.49258198e+00 -1.67310088e+00  1.56293561e+00\n",
      " -4.01178651e+00 -2.03913485e+00 -7.36501646e-01  1.40561146e+00\n",
      " -2.47316303e+00 -8.67218728e-01 -2.55334535e+00 -2.83779294e+00\n",
      "  2.41381960e+00  2.07642746e+00 -4.74847146e+00 -3.25034405e+00\n",
      "  2.61524202e+00 -1.45721271e+00 -1.84651833e+00 -3.68857269e+00\n",
      " -3.70130961e-01  2.49462469e+00 -2.49793488e+00 -2.39222150e+00\n",
      "  1.70781065e+00 -3.18268030e+00 -2.48217869e+00 -2.43642541e+00\n",
      "  1.88423727e+00 -2.77441722e+00 -7.75326791e-01 -3.08656004e+00\n",
      " -4.07168734e+00 -3.00802618e+00 -3.25873348e+00  2.78511991e+00\n",
      "  1.42856674e+00  2.48781991e+00 -2.38061362e+00 -2.73299729e+00\n",
      " -3.05681740e+00 -6.94252772e-01 -1.95875381e+00 -3.18039988e+00\n",
      " -1.70687077e+00 -2.96595693e+00 -2.72559672e+00  9.26371811e-01\n",
      " -2.58116225e+00 -1.20196193e+00 -2.27035395e+00 -2.50482805e+00\n",
      "  1.01102959e+00 -1.11059794e+00 -1.90422202e+00  1.77958182e+00\n",
      "  1.83106095e+00 -3.48054115e+00 -2.20552162e+00 -1.31926178e+00\n",
      " -1.73075570e+00 -3.44047887e+00 -3.07803478e+00  2.31813400e+00\n",
      " -2.96092503e+00 -1.78137281e+00  1.17774714e+00  2.58692188e+00\n",
      " -4.10439329e-01 -2.87906024e+00 -3.93725807e-01  1.63866299e+00\n",
      " -2.58118655e+00 -1.13259919e+00 -3.01465567e+00 -4.26940488e+00\n",
      "  1.53415563e+00 -1.52896231e+00 -1.40341669e+00 -1.98665538e+00\n",
      " -2.02089371e+00  9.86827100e-02 -3.09397261e+00 -1.82557044e+00\n",
      "  1.51965292e+00  1.66171600e+00 -1.46965880e+00 -5.18967859e-01\n",
      " -3.61596796e+00 -3.21189165e+00 -2.10387095e+00  1.43857679e+00\n",
      "  1.62739013e+00 -4.37871781e+00  1.91340639e-01  1.26680643e+00\n",
      " -3.15886486e+00 -2.88702786e+00  7.14750071e-01 -2.19989847e+00\n",
      " -3.92742773e+00 -9.09447991e-01 -2.21258187e+00 -2.26502456e+00\n",
      " -1.52053679e+00 -1.01478211e+00  1.25801163e+00 -2.96050385e+00\n",
      " -4.90491887e+00 -1.51208706e+00 -2.89498198e+00 -1.60475694e+00\n",
      "  1.29067029e+00 -2.12533331e+00 -2.35871399e+00 -2.69289706e+00\n",
      " -1.77392658e+00  1.69838135e+00  1.76788870e+00 -4.60569056e+00\n",
      " -1.05476736e+00 -1.53684553e+00 -2.03019558e+00 -1.64489776e-01\n",
      " -2.65368819e+00 -2.90844466e+00 -2.36132561e+00 -1.95908502e+00\n",
      " -1.36741031e+00  1.17752410e+00 -3.04583084e+00 -2.85564007e+00\n",
      "  1.88595818e+00 -2.86035311e+00 -2.72738337e+00  1.94012171e+00\n",
      " -2.29805101e+00 -3.41110217e+00 -3.62346618e+00  3.13542905e-01\n",
      "  8.23103775e-01 -4.10403349e-01 -2.39437271e+00 -7.31131722e-01\n",
      " -2.92960323e+00  2.61155373e+00 -2.71611071e+00 -2.40631966e+00\n",
      " -2.95551874e+00  7.53410243e-01 -1.80541362e+00 -1.37522883e+00\n",
      " -2.23745242e+00 -3.39507435e+00  2.06498244e+00 -2.82423349e+00\n",
      "  2.47700170e+00  1.64900381e+00 -1.44036969e+00 -3.17424198e+00\n",
      " -3.59765676e+00 -2.23823411e+00  1.38091236e+00  1.31759198e+00\n",
      "  1.34850781e-01 -2.35042664e+00  1.85473416e+00  1.12261790e-01\n",
      "  5.42595239e-01  6.10911511e-01  8.57486239e-01  6.21147776e-01\n",
      "  1.67975003e+00 -1.41523194e+00 -1.81379022e+00 -2.30174565e+00\n",
      "  1.81920698e+00 -2.20370315e+00 -8.31845717e-01 -3.24128863e+00\n",
      " -1.87457795e+00 -1.24403884e+00 -2.81380017e+00 -3.38627877e+00\n",
      " -4.02875022e+00 -2.74003448e+00 -2.61386888e-01 -2.02535399e+00\n",
      "  1.79592785e+00 -1.78750509e+00 -2.03293487e+00 -2.58335765e+00\n",
      "  2.43856845e+00  1.72931083e+00 -3.48168187e+00 -2.30133757e+00\n",
      " -2.67277674e+00 -3.58065901e+00 -2.03343545e+00 -1.81476396e+00\n",
      " -2.33591967e+00 -1.14505358e-01 -5.86426073e-01 -1.25973285e+00\n",
      "  1.80406795e+00 -1.78882331e+00 -2.12282046e+00 -2.04849939e+00\n",
      "  1.62193951e+00 -1.85209727e-01 -1.50150616e+00 -2.16605433e+00\n",
      " -2.04298214e+00 -1.98180406e+00 -3.99286717e+00 -2.24793763e+00\n",
      "  8.58969064e-01 -2.43235845e+00 -2.10095573e+00  8.66759995e-01\n",
      " -2.74911925e+00 -2.86545916e+00  2.07936751e+00  6.54373044e-01\n",
      " -7.36316049e-01 -3.27385084e+00 -3.58988205e+00  2.01757408e+00\n",
      " -2.12557363e+00  9.68552696e-01 -2.65499444e+00  2.22860484e+00\n",
      "  2.44336089e+00 -2.24820220e+00 -4.59459709e+00  7.57443725e-01\n",
      " -2.91941278e+00  2.02593838e+00 -1.35993871e+00 -3.94047257e+00\n",
      " -2.22844436e+00  1.60827341e+00 -1.75138726e+00 -3.41221752e+00\n",
      " -2.50689800e+00  1.00034178e+00 -2.50886977e+00 -2.75404893e+00\n",
      " -3.04817202e+00 -2.29967595e+00  1.97985466e+00  1.21461806e+00\n",
      " -4.02004367e+00  1.65427913e+00  1.24677687e+00  1.89015853e+00\n",
      " -3.09620975e+00 -2.78864010e+00 -7.45961700e-01 -2.77357339e+00\n",
      " -2.73471072e+00  1.41419210e+00  1.13262039e+00 -2.31317533e-01\n",
      " -1.47954075e+00 -2.88898679e+00 -2.87020692e+00 -2.27433515e+00\n",
      " -2.18705675e+00 -1.83732200e+00  1.58102181e+00 -2.50230494e+00\n",
      "  1.55084060e+00 -4.62727682e-01  1.19638648e-01 -6.75284957e-01\n",
      " -3.56749402e+00 -1.28275950e+00 -3.21725131e+00  9.05248186e-01\n",
      " -1.95110377e+00  3.37319430e+00  3.02497994e-01 -1.37157329e+00\n",
      " -2.15993362e+00 -3.52913120e+00 -1.06380489e+00 -3.12668822e+00\n",
      "  1.58068969e+00 -1.59384553e-01  1.93600870e+00 -2.39119973e+00\n",
      "  3.32415438e+00  4.93168697e-01  1.69273902e+00  2.20882318e+00\n",
      "  1.27088244e+00 -6.92928797e-01  1.71038393e+00 -1.21186645e+00\n",
      "  1.85694554e+00 -2.90178235e+00 -7.29058560e-01  9.72376263e-01\n",
      " -2.48114418e+00 -2.77962773e+00 -2.33942248e+00 -3.24854692e+00\n",
      "  1.33448213e+00  2.05917016e+00 -4.04217396e+00 -3.87710805e+00\n",
      " -2.88179775e+00  2.41971444e+00  1.18613036e+00 -2.49845928e+00\n",
      "  2.11902071e+00  1.70337150e+00 -2.22627202e+00 -2.30634193e+00\n",
      " -1.92896499e+00  1.16772902e+00 -1.47444767e+00  1.21841775e+00\n",
      "  1.28553535e+00 -2.80088664e+00  1.62542587e+00  5.63938946e-02\n",
      " -3.04918365e+00 -2.73605678e+00 -1.91493030e+00  3.39495874e-01\n",
      "  2.42865024e-01  1.45530689e+00 -2.90223094e-01 -1.57208030e+00\n",
      " -2.25864259e+00 -2.07376093e+00 -3.59142914e+00 -2.47432398e+00\n",
      " -4.50228397e+00 -3.05709416e+00  8.14574098e-01 -1.30174633e+00]\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(clf.decision_function(X_cv))\n",
    "print(clf.decision_function(X_cv).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0bKCboN4Zxu"
   },
   "source": [
    "<h2><font color='Geen'> 8F: Implementing Platt Scaling to find P(Y==1|X)</font></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMn7OEN94Zxw"
   },
   "source": [
    "Check this <a href='https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a'>PDF</a>\n",
    "<img src='https://i.imgur.com/CAMnVnh.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0n5EFkx4Zxz"
   },
   "source": [
    "## TASK F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0HOqVJq4Zx1"
   },
   "source": [
    "\n",
    "> 4. Apply SGD algorithm with ($f_{cv}$, $y_{cv}$) and find the weight $W$ intercept $b$ ```Note: here our data is of one dimensional so we will have a one dimensional weight vector i.e W.shape (1,)``` \n",
    "\n",
    "> Note1: Don't forget to change the values of $y_{cv}$ as mentioned in the above image. you will calculate y+, y- based on data points in train data\n",
    "\n",
    "> Note2: the Sklearn's SGD algorithm doesn't support the real valued outputs, you need to use the code that was done in the `'Logistic Regression with SGD and L2'` Assignment after modifying loss function, and use same parameters that used in that assignment.\n",
    "<img src='https://i.imgur.com/zKYE9Oc.png'>\n",
    "if Y[i] is 1, it will be replaced with y+ value else it will replaced with y- value\n",
    "\n",
    "> 5. For a given data point from $X_{test}$, $P(Y=1|X) = \\frac{1}{1+exp(-(W*f_{test}+ b))}$ where ` `$f_{test}$ ```= decision_function(```$X_{test}$```)```, W and b will be learned as metioned in the above step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTY7z2bd4Zx2"
   },
   "source": [
    "__Note: in the above algorithm, the steps 2, 4 might need hyper parameter tuning, To reduce the complexity of the assignment we are excluding the hyerparameter tuning part, but intrested students can try that__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM3odN1Z4Zx3"
   },
   "source": [
    "\n",
    "If any one wants to try other calibration algorithm istonic regression also please check these tutorials\n",
    "\n",
    "1. http://fa.bianp.net/blog/tag/scikit-learn.html#fn:1\n",
    "\n",
    "2. https://drive.google.com/open?id=1MzmA7QaP58RDzocB0RBmRiWfl7Co_VJ7\n",
    "\n",
    "3. https://drive.google.com/open?id=133odBinMOIVb_rh_GQxxsyMRyW-Zts7a\n",
    "\n",
    "4. https://stat.fandom.com/wiki/Isotonic_regression#Pool_Adjacent_Violators_Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "908\n",
      "2092\n",
      "0.9989010989010989\n",
      "0.0004775549188156638\n",
      "[0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989, 0.9989010989010989, 0.9989010989010989, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.0004775549188156638, 0.9989010989010989]\n"
     ]
    }
   ],
   "source": [
    "count_positive = 0\n",
    "count_negative = 0\n",
    "for y in y_train:\n",
    "\n",
    "    if y==1:\n",
    "        count_positive+=1\n",
    "    if y ==0:\n",
    "        count_negative+=1\n",
    "print(count_positive)   \n",
    "print(count_negative)\n",
    "        \n",
    "y_plus =  (count_positive+1)/(count_positive+2)       \n",
    "y_negative = 1/(count_negative+2)\n",
    "\n",
    "print(y_plus)\n",
    "print(y_negative)\n",
    "\n",
    "y_cv_new = []\n",
    "for i in range(len(y_cv)):\n",
    "\n",
    "    if y_cv[i]==0:\n",
    "        y_cv_new.append(y_negative)\n",
    "    \n",
    "    elif y_cv[i]==1:\n",
    "        y_cv_new.append(y_plus) \n",
    "        \n",
    "        \n",
    "print(y_cv_new)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "    b = 0\n",
    "    \n",
    "    x = np.arange(1,len(dim)+1)\n",
    "    w = np.zeros_like(x,dtype=float)\n",
    "    return w,b\n",
    "\n",
    "\n",
    "def sigmoid(z): \n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "    return (1/(1+math.exp(-z)))\n",
    "\n",
    "   \n",
    "def logloss(y_true,y_pred):\n",
    "\n",
    "    '''In this function, we will compute log loss '''\n",
    "    n=len(y_true)\n",
    "    numerator = 0\n",
    "    for i in range(n):\n",
    "        numerator += (y_true[i]*math.log(y_pred[i],10)+(1-y_true[i])*math.log(1-y_pred[i],10))\n",
    "    loss = (-numerator/n) \n",
    "                         \n",
    "    return loss\n",
    "\n",
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    \n",
    "    dw =x*(y-sigmoid(np.dot(w,x)+b))-((alpha*w)/N)       \n",
    "    return dw    \n",
    "                                                   \n",
    "    \n",
    "def gradient_db(x,y,w,b):\n",
    "     '''In this function, we will compute gradient w.r.to b '''\n",
    "    \n",
    "     db = y-sigmoid(np.dot(np.transpose(w),x)+ b)\n",
    "     return db\n",
    "\n",
    "\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def train(fcv,y_cv_new,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''    \n",
    "    #Here eta0 is learning rate\n",
    "    #implement the code as follows\n",
    "    # initalize the weights (call the initialize_weights(X_train[0]) function)\n",
    "    # for every epoch\n",
    "        # for every data point(X_train,y_train)\n",
    "           #compute gradient w.r.to w (call the gradient_dw() function)\n",
    "           #compute gradient w.r.to b (call the gradient_db() function)\n",
    "           #update w, b\n",
    "        # predict the output of x_train[for all data points in X_train] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the train loss values in a list\n",
    "        # predict the output of x_test[for all data points in X_test] using w,b\n",
    "        #compute the loss between predicted and actual values (call the loss function)\n",
    "        # store all the test loss values in a list\n",
    "        # you can also compare previous loss and current loss, if loss is not updating then stop the process and return w,b\n",
    "    cv_loss = []\n",
    "    predict_cv =[]\n",
    "       \n",
    "    dim=fcv[0] \n",
    "    loss=0\n",
    "    w,b = initialize_weights(dim)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        for x,y in zip(fcv,y_cv_new):\n",
    "            grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "            grad_db=gradient_db(x,y,w,b)\n",
    "            w = w + eta0*grad_dw\n",
    "            b = b + eta0*grad_db           \n",
    "        predict_cv = pred(w,b,fcv)\n",
    "        loss=logloss(y_cv_new,predict_cv)\n",
    "        cv_loss.append(loss)\n",
    "#         predict_test = pred(w,b,X_test)\n",
    "#         loss = logloss(y_test,predict_test)\n",
    "#         test_loss.append(loss)\n",
    "       \n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "    epochs = [i for i in range(1,51)]\n",
    "#     plt.scatter(epochs, train_loss, label='Train_Loss')\n",
    "    plt.scatter(epochs, cv_loss, label='CV_Loss')\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"LogLoss\")\n",
    "    plt.title(\"Epochs vs LogLoss\")\n",
    "    plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "    plt.show()\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Weight Vector Is: [1.19788585]\n",
      "Optimal Intercept Is -0.09076579013198308\n"
     ]
    }
   ],
   "source": [
    "alpha=0.0001 #Regularization(lambda)\n",
    "eta0=0.0001 #Learning rate\n",
    "N=len(fcv)\n",
    "epochs=50\n",
    "w,b=train(fcv,y_cv_new,epochs,alpha,eta0)\n",
    "print(\"Optimal Weight Vector Is:\", w)\n",
    "print(\"Optimal Intercept Is\",b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(w,b,X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        predict.append(sigmoid(z))\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conditional Probability With Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Probability,P(Y==1|Xtest) [0.86200777]\n",
      "Actual Value is: 1\n",
      "Conditional Probability,P(Y==1|Xtest) [0.01095213]\n",
      "Actual Value is: 0\n",
      "Conditional Probability,P(Y==1|Xtest) [0.03766366]\n",
      "Actual Value is: 0\n",
      "Conditional Probability,P(Y==1|Xtest) [0.09065251]\n",
      "Actual Value is: 0\n",
      "Conditional Probability,P(Y==1|Xtest) [0.84135747]\n",
      "Actual Value is: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "     print(\"Conditional Probability,P(Y==1|Xtest)\",1/(1+np.exp(-(w*ftest[i]+b))))\n",
    "     print(\"Actual Value is:\" ,y_test[i])   \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8E&F_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
