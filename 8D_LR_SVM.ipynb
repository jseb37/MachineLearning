{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86Tvnj5UblTy"
   },
   "source": [
    "## Task-D: Collinear features and their effect on linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qn_eOn2EblT3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VMoYWIayblUB"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('task_d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RfStXG4tblUI",
    "outputId": "ddf4eec6-7f53-4d28-914f-23133957d6d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w  \\\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277   \n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364   \n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738   \n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720   \n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JIIuomCkblUP"
   },
   "outputs": [],
   "source": [
    "X = data.drop(['target'], axis=1).values\n",
    "Y = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = data.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>x*x</th>\n",
       "      <th>2*y</th>\n",
       "      <th>2*z+3*x*x</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.581066</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.604025</td>\n",
       "      <td>0.841837</td>\n",
       "      <td>-0.665927</td>\n",
       "      <td>-0.536277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.894309</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.883052</td>\n",
       "      <td>-0.207835</td>\n",
       "      <td>-0.917054</td>\n",
       "      <td>-0.522364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.207552</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.082312</td>\n",
       "      <td>-1.150918</td>\n",
       "      <td>0.212034</td>\n",
       "      <td>-1.166507</td>\n",
       "      <td>0.205738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.364174</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-0.943643</td>\n",
       "      <td>-1.280666</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>-1.266540</td>\n",
       "      <td>-0.665720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.737687</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-1.012978</td>\n",
       "      <td>-0.744934</td>\n",
       "      <td>1.051772</td>\n",
       "      <td>-0.792746</td>\n",
       "      <td>-0.735054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x         y         z       x*x       2*y  2*z+3*x*x         w\n",
       "0 -0.581066  0.841837 -1.012978 -0.604025  0.841837  -0.665927 -0.536277\n",
       "1 -0.894309 -0.207835 -1.012978 -0.883052 -0.207835  -0.917054 -0.522364\n",
       "2 -1.207552  0.212034 -1.082312 -1.150918  0.212034  -1.166507  0.205738\n",
       "3 -1.364174  0.002099 -0.943643 -1.280666  0.002099  -1.266540 -0.665720\n",
       "4 -0.737687  1.051772 -1.012978 -0.744934  1.051772  -0.792746 -0.735054"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.58663321e-01 -6.27704002e-01  1.13639313e+00  3.00024267e-01\n",
      "  -6.27704002e-01  4.07223826e-01 -5.05432967e-02]\n",
      " [ 4.54202458e-02 -1.46744180e+00  5.81716801e-01 -1.24864784e-02\n",
      "  -1.46744180e+00  5.89939855e-02  1.38043580e-01]\n",
      " [-1.05093052e+00  6.31902691e-01 -8.74308565e-01 -1.01838044e+00\n",
      "   6.31902691e-01 -1.02210899e+00 -1.67303624e+00]\n",
      " [ 5.15284858e-01  1.89150938e+00 -1.15164673e+00  4.60465051e-01\n",
      "   1.89150938e+00  2.75381999e-01 -8.36756163e-01]\n",
      " [ 1.76825716e+00 -4.17769553e-01  1.20572767e+00  1.84444121e+00\n",
      "  -4.17769553e-01  1.80558428e+00  1.08190246e+00]\n",
      " [ 1.14177101e+00 -1.88731069e+00  1.13639313e+00  1.13013093e+00\n",
      "  -1.88731069e+00  1.15432751e+00  5.61001444e-01]\n",
      " [-7.37687441e-01  1.05177159e+00 -1.01297765e+00 -7.44933538e-01\n",
      "   1.05177159e+00 -7.92746068e-01 -7.35054120e-01]\n",
      " [ 3.58663321e-01  2.73124718e+00 -9.43643106e-01  3.00024267e-01\n",
      "   2.73124718e+00  1.56096537e-01 -1.44650062e-01]\n",
      " [ 1.29839254e+00  4.21968242e-01  1.27506221e+00  1.30452309e+00\n",
      "   4.21968242e-01  1.32802388e+00  1.24065846e+00]\n",
      " [-7.37687441e-01  6.31902691e-01 -8.74308565e-01 -7.44933538e-01\n",
      "   6.31902691e-01 -7.76004249e-01 -1.04470299e+00]\n",
      " [-4.24444366e-01 -8.37638451e-01  7.20385883e-01 -4.60325538e-01\n",
      "  -8.37638451e-01 -3.27323493e-01 -6.55300133e-01]\n",
      " [ 2.02041783e-01 -2.07835104e-01  1.13639313e+00  1.42373757e-01\n",
      "  -2.07835104e-01  2.65336908e-01  1.04153762e+00]\n",
      " [ 4.54202458e-02 -1.46744180e+00  6.51051342e-01 -1.24864784e-02\n",
      "  -1.46744180e+00  6.73648952e-02 -3.30207602e-01]\n",
      " [ 4.54202458e-02 -1.25750735e+00  7.89720424e-01 -1.24864784e-02\n",
      "  -1.25750735e+00  8.41067144e-02 -3.19664743e-01]\n",
      " [-1.67741667e+00 -4.17769553e-01 -1.01297765e+00 -1.53179095e+00\n",
      "  -4.17769553e-01 -1.50092502e+00  1.63838184e-01]\n",
      " [ 9.85149470e-01 -6.27704002e-01  7.89720424e-01  9.58529052e-01\n",
      "  -6.27704002e-01  9.58029679e-01 -2.03456479e-01]\n",
      " [ 2.02041783e-01 -2.07835104e-01  8.59054966e-01  1.42373757e-01\n",
      "  -2.07835104e-01  2.31853269e-01 -1.87566588e-02]\n",
      " [-8.94308978e-01  2.09934449e-03 -9.43643106e-01 -8.83052126e-01\n",
      "   2.09934449e-03 -9.08683166e-01 -1.14312018e-01]\n",
      " [-7.37687441e-01  6.31902691e-01 -9.43643106e-01 -7.44933538e-01\n",
      "   6.31902691e-01 -7.84375159e-01 -1.87525510e+00]\n",
      " [-5.81065904e-01  1.47164049e+00 -9.43643106e-01 -6.04024675e-01\n",
      "   1.47164049e+00 -6.57555878e-01  3.95229696e-01]\n",
      " [-2.67822829e-01  1.26170604e+00 -9.43643106e-01 -3.13836126e-01\n",
      "   1.26170604e+00 -3.96383498e-01 -1.35689221e+00]\n",
      " [ 3.58663321e-01 -4.17769553e-01  9.28389507e-01  3.00024267e-01\n",
      "  -4.17769553e-01  3.82111097e-01  1.84126905e+00]\n",
      " [ 1.14177101e+00 -4.17769553e-01  9.97724048e-01  1.13013093e+00\n",
      "  -4.17769553e-01  1.13758569e+00  1.98596718e-02]\n",
      " [-5.81065904e-01  4.21968242e-01 -8.04974023e-01 -6.04024675e-01\n",
      "   4.21968242e-01 -6.40814059e-01 -9.79958255e-02]\n",
      " [ 4.54202458e-02 -1.04757290e+00  1.06705859e+00 -1.24864784e-02\n",
      "  -1.04757290e+00  1.17590353e-01  6.33419092e-01]\n",
      " [-5.81065904e-01  1.26170604e+00 -9.43643106e-01 -6.04024675e-01\n",
      "   1.26170604e+00 -6.57555878e-01 -1.18216914e+00]\n",
      " [-1.36417359e+00  6.31902691e-01 -1.01297765e+00 -1.28066624e+00\n",
      "   6.31902691e-01 -1.27491046e+00  3.68155902e-01]\n",
      " [-7.37687441e-01  4.21968242e-01 -1.01297765e+00 -7.44933538e-01\n",
      "   4.21968242e-01 -7.92746068e-01  1.13548931e-01]\n",
      " [-1.05093052e+00 -2.07835104e-01 -1.01297765e+00 -1.01838044e+00\n",
      "  -2.07835104e-01 -1.03885081e+00 -1.66480188e+00]\n",
      " [ 3.58663321e-01 -2.07835104e-01  9.28389507e-01  3.00024267e-01\n",
      "  -2.07835104e-01  3.82111097e-01  1.71647571e+00]\n",
      " [ 2.02041783e-01 -4.17769553e-01  5.12382260e-01  1.42373757e-01\n",
      "  -4.17769553e-01  1.89998721e-01 -3.47314072e-01]\n",
      " [-5.81065904e-01  8.41837140e-01 -1.01297765e+00 -6.04024675e-01\n",
      "   8.41837140e-01 -6.65926787e-01 -4.06519765e-01]\n",
      " [ 3.58663321e-01  1.47164049e+00 -8.04974023e-01  3.00024267e-01\n",
      "   1.47164049e+00  1.72838356e-01  2.70811007e-03]\n",
      " [ 1.29839254e+00 -1.67737625e+00  1.06705859e+00  1.30452309e+00\n",
      "  -1.67737625e+00  1.30291115e+00  9.30762903e-01]\n",
      " [-1.11201292e-01  6.31902691e-01 -8.04974023e-01 -1.64556439e-01\n",
      "   6.31902691e-01 -2.45288579e-01 -1.61253425e+00]\n",
      " [-8.94308978e-01 -1.46744180e+00  3.04378636e-01 -8.83052126e-01\n",
      "  -1.46744180e+00 -7.58006793e-01  1.01070437e+00]\n",
      " [-1.11201292e-01 -2.07835104e-01  1.13639313e+00 -1.64556439e-01\n",
      "  -2.07835104e-01 -1.09031098e-02  7.38113409e-02]\n",
      " [-5.81065904e-01  1.47164049e+00 -6.66304941e-01 -6.04024675e-01\n",
      "   1.47164049e+00 -6.24072239e-01 -1.39303650e+00]\n",
      " [ 1.45501408e+00 -4.17769553e-01  9.97724048e-01  1.48170552e+00\n",
      "  -4.17769553e-01  1.45400607e+00  9.49332468e-02]\n",
      " [ 5.15284858e-01 -8.37638451e-01  8.59054966e-01  4.60465051e-01\n",
      "  -8.37638451e-01  5.18138378e-01  7.34046160e-01]\n",
      " [-1.36417359e+00  1.05177159e+00 -1.29031581e+00 -1.28066624e+00\n",
      "   1.05177159e+00 -1.30839410e+00 -1.51203058e+00]\n",
      " [-4.24444366e-01  2.10144383e+00 -9.43643106e-01 -4.60325538e-01\n",
      "   2.10144383e+00 -5.28225324e-01  2.78895657e-01]\n",
      " [-7.37687441e-01 -2.07835104e-01 -8.74308565e-01 -7.44933538e-01\n",
      "  -2.07835104e-01 -7.76004249e-01 -7.79964001e-01]\n",
      " [-8.94308978e-01  2.09934449e-03 -9.43643106e-01 -8.83052126e-01\n",
      "   2.09934449e-03 -9.08683166e-01  2.56013375e-01]\n",
      " [-1.67741667e+00 -2.07835104e-01 -1.08231219e+00 -1.53179095e+00\n",
      "  -2.07835104e-01 -1.50929593e+00 -4.72829093e-02]\n",
      " [-7.37687441e-01  2.12033793e-01 -1.15164673e+00 -7.44933538e-01\n",
      "   2.12033793e-01 -8.09487887e-01 -1.03823234e+00]\n",
      " [ 6.71906395e-01  2.12033793e-01  1.34439675e+00  6.23696110e-01\n",
      "   2.12033793e-01  7.23644209e-01  5.13102602e-01]\n",
      " [ 8.28527933e-01  6.31902691e-01  1.13639313e+00  7.89717444e-01\n",
      "   6.31902691e-01  8.47952217e-01  1.02133893e+00]\n",
      " [ 9.85149470e-01 -4.17769553e-01  1.27506221e+00  9.58529052e-01\n",
      "  -4.17769553e-01  1.01662605e+00 -2.93345802e-01]\n",
      " [-7.37687441e-01 -2.30717959e+00  4.43047718e-01 -7.44933538e-01\n",
      "  -2.30717959e+00 -6.16956966e-01 -4.58214787e-01]\n",
      " [-5.81065904e-01  6.31902691e-01 -9.43643106e-01 -6.04024675e-01\n",
      "   6.31902691e-01 -6.57555878e-01 -1.89048402e+00]\n",
      " [-7.37687441e-01 -1.67737625e+00  3.04378636e-01 -7.44933538e-01\n",
      "  -1.67737625e+00 -6.33698785e-01  1.36351540e+00]\n",
      " [-1.11201292e-01  1.68157493e+00 -8.04974023e-01 -1.64556439e-01\n",
      "   1.68157493e+00 -2.45288579e-01  4.89915854e-01]\n",
      " [ 8.28527933e-01 -8.37638451e-01  1.55240038e+00  7.89717444e-01\n",
      "  -8.37638451e-01  8.98177675e-01  1.94454083e+00]\n",
      " [ 2.23812177e+00  2.09934449e-03  1.41373130e+00  2.40947180e+00\n",
      "   2.09934449e-03  2.33922977e+00  1.67479348e+00]\n",
      " [ 5.15284858e-01 -8.37638451e-01  7.20385883e-01  4.60465051e-01\n",
      "  -8.37638451e-01  5.01396559e-01  1.28012377e+00]\n",
      " [-1.36417359e+00  2.09934449e-03 -9.43643106e-01 -1.28066624e+00\n",
      "   2.09934449e-03 -1.26653955e+00 -6.65719960e-01]\n",
      " [ 2.39474331e+00  2.12033793e-01  1.27506221e+00  2.60339588e+00\n",
      "   2.12033793e-01  2.49702141e+00  1.57480018e+00]\n",
      " [-5.81065904e-01  8.41837140e-01 -1.01297765e+00 -6.04024675e-01\n",
      "   8.41837140e-01 -6.65926787e-01 -5.36277029e-01]\n",
      " [ 1.29839254e+00 -1.25750735e+00  1.41373130e+00  1.30452309e+00\n",
      "  -1.25750735e+00  1.34476570e+00  1.88555113e+00]\n",
      " [ 1.76825716e+00 -2.07835104e-01  1.06705859e+00  1.84444121e+00\n",
      "  -2.07835104e-01  1.78884246e+00  1.14984834e-01]\n",
      " [ 9.85149470e-01 -2.07835104e-01  1.20572767e+00  9.58529052e-01\n",
      "  -2.07835104e-01  1.00825514e+00  4.75447081e-01]\n",
      " [-1.05093052e+00 -2.07835104e-01 -1.01297765e+00 -1.01838044e+00\n",
      "  -2.07835104e-01 -1.03885081e+00 -1.43304574e+00]\n",
      " [-1.11201292e-01  6.31902691e-01 -9.43643106e-01 -1.64556439e-01\n",
      "   6.31902691e-01 -2.62030398e-01  5.03334896e-01]\n",
      " [-1.05093052e+00  6.31902691e-01 -6.66304941e-01 -1.01838044e+00\n",
      "   6.31902691e-01 -9.96996263e-01  3.40778294e-01]\n",
      " [-7.37687441e-01  8.41837140e-01 -1.08231219e+00 -7.44933538e-01\n",
      "   8.41837140e-01 -8.01116978e-01 -1.20189106e+00]\n",
      " [-5.81065904e-01  1.47164049e+00 -8.74308565e-01 -6.04024675e-01\n",
      "   1.47164049e+00 -6.49184968e-01 -1.06009817e+00]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, stratify=Y)\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ydm98u3EblUU"
   },
   "source": [
    "### Doing perturbation test to check the presence of collinearity  \n",
    "\n",
    "#### Task: 1 Logistic Regression\n",
    "<pre>\n",
    "\n",
    "\n",
    "1. <b>Finding the Correlation between the features</b>\n",
    "    a. check the correlation between the features\n",
    "    b. plot heat map of correlation matrix using seaborn heatmap\n",
    "2. <b>Finding the best model for the given data</b>\n",
    "    a. Train Logistic regression on data(X,Y) that we have created in the above cell\n",
    "    b. Find the best hyper prameter alpha with hyper parameter tuning using k-fold cross validation (grid search CV or         \n",
    "    random search CV make sure you choose the alpha in log space)\n",
    "    c. Creat a new Logistic regression with the best alpha\n",
    "    (search for how to get the best hyper parameter value), name the best model as 'best_model'\n",
    "    \n",
    "3. <b>Getting the weights with the original data</b>\n",
    "    a. train the 'best_model' with X, Y\n",
    "    b. Check the accuracy of the model 'best_model_accuracy'\n",
    "    c. Get the weights W using best_model.coef_\n",
    "\n",
    "4. <b>Modifying original data</b>\n",
    "    a. Add a noise(order of 10^-2) to each element of X \n",
    "    and get the new data set X' (X' = X + e)\n",
    "    b. Train the same 'best_model' with data (X', Y)\n",
    "    c. Check the accuracy of the model 'best_model_accuracy_edited'\n",
    "    d. Get the weights W' using best_model.coef_\n",
    "    \n",
    "5. <b> Checking deviations in metric and weights </b>\n",
    "    a. find the difference between 'best_model_accuracy_edited' and 'best_model_accuracy'\n",
    "    b. find the absolute change between each value of W and W' ==> |(W-W')|\n",
    "    c. print the top 4 features which have higher % change in weights \n",
    "    compare to the other feature\n",
    "\n",
    "</pre>\n",
    "\n",
    "#### Task: 2 Linear SVM\n",
    "\n",
    "<pre>\n",
    "1. Do the same steps (2, 3, 4, 5) we have done in the above task 1.\n",
    "</pre>\n",
    "\n",
    "<strong><font color='red'>Do write the observations based on the results you get from the deviations of weights in both Logistic Regression and linear SVM</font></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lai8wXU1pmSb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  x         y         z       x*x       2*y  2*z+3*x*x  \\\n",
      "x          1.000000 -0.205926  0.812458  0.997947 -0.205926   0.996252   \n",
      "y         -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
      "z          0.812458 -0.602663  1.000000  0.807137 -0.602663   0.847163   \n",
      "x*x        0.997947 -0.209289  0.807137  1.000000 -0.209289   0.997457   \n",
      "2*y       -0.205926  1.000000 -0.602663 -0.209289  1.000000  -0.261123   \n",
      "2*z+3*x*x  0.996252 -0.261123  0.847163  0.997457 -0.261123   1.000000   \n",
      "w          0.583277 -0.401790  0.674486  0.583803 -0.401790   0.606860   \n",
      "\n",
      "                  w  \n",
      "x          0.583277  \n",
      "y         -0.401790  \n",
      "z          0.674486  \n",
      "x*x        0.583803  \n",
      "2*y       -0.401790  \n",
      "2*z+3*x*x  0.606860  \n",
      "w          1.000000  \n"
     ]
    }
   ],
   "source": [
    "X_data_corr = X_data.corr()\n",
    "print(X_data_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a735254240>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns    \n",
    "\n",
    "#annot -If True, write the data value in each cell\n",
    "sns.heatmap(X_data_corr, annot=True,cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 75.06, NNZs: 7, Bias: -8.828554, T: 44, Avg. loss: 1.410734\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 74.48, NNZs: 7, Bias: -8.828554, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 73.91, NNZs: 7, Bias: -8.828554, T: 132, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 73.35, NNZs: 7, Bias: -8.828554, T: 176, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 72.80, NNZs: 7, Bias: -8.828554, T: 220, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 72.25, NNZs: 7, Bias: -8.828554, T: 264, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 71.72, NNZs: 7, Bias: -8.828554, T: 308, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 88.69, NNZs: 7, Bias: 44.441184, T: 45, Avg. loss: 1.382474\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 87.99, NNZs: 7, Bias: 44.441184, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 87.31, NNZs: 7, Bias: 44.441184, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 86.63, NNZs: 7, Bias: 44.441184, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 85.96, NNZs: 7, Bias: 44.441184, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 85.31, NNZs: 7, Bias: 44.441184, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 84.66, NNZs: 7, Bias: 44.441184, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 18.17, NNZs: 7, Bias: 9.246501, T: 45, Avg. loss: 0.015966\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 18.06, NNZs: 7, Bias: 9.219703, T: 90, Avg. loss: 0.000063\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.95, NNZs: 7, Bias: 9.193965, T: 135, Avg. loss: 0.000056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 17.84, NNZs: 7, Bias: 9.168245, T: 180, Avg. loss: 0.000051\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 17.73, NNZs: 7, Bias: 9.143224, T: 225, Avg. loss: 0.000049\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.62, NNZs: 7, Bias: 9.118527, T: 270, Avg. loss: 0.000047\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 17.51, NNZs: 7, Bias: 9.094790, T: 315, Avg. loss: 0.000043\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 15.89, NNZs: 7, Bias: 3.256185, T: 44, Avg. loss: 0.056544\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.25, NNZs: 7, Bias: 3.256126, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 14.65, NNZs: 7, Bias: 3.256031, T: 132, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 14.10, NNZs: 7, Bias: 3.255808, T: 176, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.60, NNZs: 7, Bias: 3.255538, T: 220, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 13.12, NNZs: 7, Bias: 3.255045, T: 264, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 12.68, NNZs: 7, Bias: 3.254431, T: 308, Avg. loss: 0.000003\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 23.10, NNZs: 7, Bias: 14.281727, T: 45, Avg. loss: 0.190554\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 22.14, NNZs: 7, Bias: 14.281718, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 21.26, NNZs: 7, Bias: 14.281676, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 20.45, NNZs: 7, Bias: 14.281552, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 19.70, NNZs: 7, Bias: 14.281294, T: 225, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 19.00, NNZs: 7, Bias: 14.280595, T: 270, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 18.35, NNZs: 7, Bias: 14.278787, T: 315, Avg. loss: 0.000005\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 17.08, NNZs: 7, Bias: 5.000102, T: 45, Avg. loss: 0.015404\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 16.37, NNZs: 7, Bias: 5.000211, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.72, NNZs: 7, Bias: 5.000334, T: 135, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.12, NNZs: 7, Bias: 5.000441, T: 180, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 14.57, NNZs: 7, Bias: 5.000559, T: 225, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 14.05, NNZs: 7, Bias: 5.000606, T: 270, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 13.57, NNZs: 7, Bias: 5.000609, T: 315, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 9.75, NNZs: 7, Bias: -0.645650, T: 44, Avg. loss: 0.039223\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.19, NNZs: 7, Bias: -0.553842, T: 88, Avg. loss: 0.000535\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.12, NNZs: 7, Bias: -0.415515, T: 132, Avg. loss: 0.001014\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.33, NNZs: 7, Bias: -0.297256, T: 176, Avg. loss: 0.001042\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.74, NNZs: 7, Bias: -0.176083, T: 220, Avg. loss: 0.001267\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.31, NNZs: 7, Bias: -0.047300, T: 264, Avg. loss: 0.001670\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 5.00, NNZs: 7, Bias: 0.084988, T: 308, Avg. loss: 0.002083\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 18.40, NNZs: 7, Bias: -0.370940, T: 45, Avg. loss: 0.385909\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 15.30, NNZs: 7, Bias: -0.368431, T: 90, Avg. loss: 0.000013\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 13.10, NNZs: 7, Bias: -0.354289, T: 135, Avg. loss: 0.000098\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.45, NNZs: 7, Bias: -0.339785, T: 180, Avg. loss: 0.000103\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 10.18, NNZs: 7, Bias: -0.311625, T: 225, Avg. loss: 0.000236\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 9.18, NNZs: 7, Bias: -0.269018, T: 270, Avg. loss: 0.000412\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 8.36, NNZs: 7, Bias: -0.216231, T: 315, Avg. loss: 0.000574\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 6.43, NNZs: 7, Bias: -1.091436, T: 45, Avg. loss: 0.023466\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 5.70, NNZs: 7, Bias: -0.634037, T: 90, Avg. loss: 0.002666\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 5.19, NNZs: 7, Bias: -0.301830, T: 135, Avg. loss: 0.002498\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 4.84, NNZs: 7, Bias: -0.047080, T: 180, Avg. loss: 0.002619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 4.61, NNZs: 7, Bias: 0.135691, T: 225, Avg. loss: 0.002925\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 4.44, NNZs: 7, Bias: 0.268023, T: 270, Avg. loss: 0.002954\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.35, NNZs: 7, Bias: 0.393651, T: 315, Avg. loss: 0.003416\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 2.80, NNZs: 7, Bias: 0.535028, T: 44, Avg. loss: 0.036998\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.61, NNZs: 7, Bias: 0.423109, T: 88, Avg. loss: 0.018382\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.58, NNZs: 7, Bias: 0.400138, T: 132, Avg. loss: 0.019858\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.59, NNZs: 7, Bias: 0.381653, T: 176, Avg. loss: 0.020829\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.58, NNZs: 7, Bias: 0.355738, T: 220, Avg. loss: 0.019848\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.56, NNZs: 7, Bias: 0.345513, T: 264, Avg. loss: 0.019574\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.55, NNZs: 7, Bias: 0.338419, T: 308, Avg. loss: 0.019937\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 3.08, NNZs: 7, Bias: 1.299565, T: 45, Avg. loss: 0.027653\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.66, NNZs: 7, Bias: 0.980389, T: 90, Avg. loss: 0.015434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.55, NNZs: 7, Bias: 0.811187, T: 135, Avg. loss: 0.016870\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.56, NNZs: 7, Bias: 0.702683, T: 180, Avg. loss: 0.018845\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.53, NNZs: 7, Bias: 0.646262, T: 225, Avg. loss: 0.018160\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.52, NNZs: 7, Bias: 0.605612, T: 270, Avg. loss: 0.017981\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.51, NNZs: 7, Bias: 0.572071, T: 315, Avg. loss: 0.018045\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 3.03, NNZs: 7, Bias: 1.621725, T: 45, Avg. loss: 0.039240\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.78, NNZs: 7, Bias: 1.160867, T: 90, Avg. loss: 0.017892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.70, NNZs: 7, Bias: 0.995862, T: 135, Avg. loss: 0.019743\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.70, NNZs: 7, Bias: 0.864234, T: 180, Avg. loss: 0.021456\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 2.68, NNZs: 7, Bias: 0.811002, T: 225, Avg. loss: 0.020657\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.65, NNZs: 7, Bias: 0.763044, T: 270, Avg. loss: 0.020087\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 2.64, NNZs: 7, Bias: 0.736944, T: 315, Avg. loss: 0.020737\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 1.42, NNZs: 7, Bias: -0.165258, T: 44, Avg. loss: 0.115518\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.38, NNZs: 7, Bias: -0.053832, T: 88, Avg. loss: 0.097405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.37, NNZs: 7, Bias: -0.011572, T: 132, Avg. loss: 0.098173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.36, NNZs: 7, Bias: 0.012831, T: 176, Avg. loss: 0.096900\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.35, NNZs: 7, Bias: 0.027306, T: 220, Avg. loss: 0.097137\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.35, NNZs: 7, Bias: 0.037644, T: 264, Avg. loss: 0.096590\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.35, NNZs: 7, Bias: 0.044729, T: 308, Avg. loss: 0.097536\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 1.54, NNZs: 7, Bias: 0.960269, T: 45, Avg. loss: 0.107410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.47, NNZs: 7, Bias: 0.703507, T: 90, Avg. loss: 0.090042\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.41, NNZs: 7, Bias: 0.584942, T: 135, Avg. loss: 0.084744\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.39, NNZs: 7, Bias: 0.514153, T: 180, Avg. loss: 0.087928\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.39, NNZs: 7, Bias: 0.465685, T: 225, Avg. loss: 0.089201\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.38, NNZs: 7, Bias: 0.430730, T: 270, Avg. loss: 0.088276\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.37, NNZs: 7, Bias: 0.403385, T: 315, Avg. loss: 0.089109\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.37, NNZs: 7, Bias: 0.381097, T: 360, Avg. loss: 0.089297\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 1.44, NNZs: 7, Bias: 0.052401, T: 45, Avg. loss: 0.137063\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.40, NNZs: 7, Bias: 0.131620, T: 90, Avg. loss: 0.101812\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.39, NNZs: 7, Bias: 0.168268, T: 135, Avg. loss: 0.102857\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.38, NNZs: 7, Bias: 0.186957, T: 180, Avg. loss: 0.101818\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.38, NNZs: 7, Bias: 0.200252, T: 225, Avg. loss: 0.102252\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.38, NNZs: 7, Bias: 0.209130, T: 270, Avg. loss: 0.102411\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.38, NNZs: 7, Bias: 0.215317, T: 315, Avg. loss: 0.102317\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.73, NNZs: 7, Bias: -0.201606, T: 44, Avg. loss: 0.258592\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.153263, T: 88, Avg. loss: 0.244517\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.131999, T: 132, Avg. loss: 0.243959\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.118067, T: 176, Avg. loss: 0.244236\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.71, NNZs: 7, Bias: -0.108455, T: 220, Avg. loss: 0.244152\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.71, NNZs: 7, Bias: -0.100743, T: 264, Avg. loss: 0.243879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.71, NNZs: 7, Bias: -0.095221, T: 308, Avg. loss: 0.244075\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.74, NNZs: 7, Bias: 0.236556, T: 45, Avg. loss: 0.250680\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.73, NNZs: 7, Bias: 0.185249, T: 90, Avg. loss: 0.229109\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.73, NNZs: 7, Bias: 0.166898, T: 135, Avg. loss: 0.233478\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.153791, T: 180, Avg. loss: 0.232166\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.144353, T: 225, Avg. loss: 0.232126\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.137717, T: 270, Avg. loss: 0.232881\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.132151, T: 315, Avg. loss: 0.232123\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.73, NNZs: 7, Bias: -0.083241, T: 45, Avg. loss: 0.274194\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.043518, T: 90, Avg. loss: 0.257410\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.026418, T: 135, Avg. loss: 0.257700\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.012649, T: 180, Avg. loss: 0.256882\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.72, NNZs: 7, Bias: -0.003630, T: 225, Avg. loss: 0.257634\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.003506, T: 270, Avg. loss: 0.256546\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.72, NNZs: 7, Bias: 0.008578, T: 315, Avg. loss: 0.256300\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.320190, T: 44, Avg. loss: 0.325212\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.279456, T: 88, Avg. loss: 0.308257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.256279, T: 132, Avg. loss: 0.305796\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.241748, T: 176, Avg. loss: 0.305215\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.230231, T: 220, Avg. loss: 0.304573\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.221360, T: 264, Avg. loss: 0.304661\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.214182, T: 308, Avg. loss: 0.304415\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.207960, T: 352, Avg. loss: 0.303955\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.250282, T: 45, Avg. loss: 0.313235\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.209019, T: 90, Avg. loss: 0.299391\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.194653, T: 135, Avg. loss: 0.299005\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.183003, T: 180, Avg. loss: 0.296318\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.174509, T: 225, Avg. loss: 0.297111\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.167322, T: 270, Avg. loss: 0.296712\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.161385, T: 315, Avg. loss: 0.296073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.156732, T: 360, Avg. loss: 0.296384\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.152471, T: 405, Avg. loss: 0.296139\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.191972, T: 45, Avg. loss: 0.322772\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.192279, T: 90, Avg. loss: 0.321816\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.177962, T: 135, Avg. loss: 0.314549\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.173256, T: 180, Avg. loss: 0.317466\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.167721, T: 225, Avg. loss: 0.315949\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.163546, T: 270, Avg. loss: 0.315692\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.160152, T: 315, Avg. loss: 0.316338\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.157621, T: 360, Avg. loss: 0.316772\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.070884, T: 44, Avg. loss: 0.354417\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.065564, T: 88, Avg. loss: 0.331272\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.058229, T: 132, Avg. loss: 0.332192\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.055799, T: 176, Avg. loss: 0.333735\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.053715, T: 220, Avg. loss: 0.334121\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.052376, T: 264, Avg. loss: 0.333912\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.051050, T: 308, Avg. loss: 0.333988\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.148805, T: 45, Avg. loss: 0.342208\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.135672, T: 90, Avg. loss: 0.327002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.129782, T: 135, Avg. loss: 0.327180\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.123287, T: 180, Avg. loss: 0.325085\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.117839, T: 225, Avg. loss: 0.323944\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.113447, T: 270, Avg. loss: 0.324760\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.110204, T: 315, Avg. loss: 0.325181\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.51, NNZs: 7, Bias: 0.107182, T: 360, Avg. loss: 0.324729\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.104860, T: 405, Avg. loss: 0.324888\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.50, NNZs: 7, Bias: 0.102665, T: 450, Avg. loss: 0.324796\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.211947, T: 45, Avg. loss: 0.369815\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.174155, T: 90, Avg. loss: 0.358265\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.154441, T: 135, Avg. loss: 0.355936\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.142472, T: 180, Avg. loss: 0.355873\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.132996, T: 225, Avg. loss: 0.354238\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.126207, T: 270, Avg. loss: 0.354612\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.120381, T: 315, Avg. loss: 0.354121\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.115380, T: 360, Avg. loss: 0.354408\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.111137, T: 405, Avg. loss: 0.354073\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.107690, T: 450, Avg. loss: 0.353866\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 10 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.206983, T: 44, Avg. loss: 0.608108\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.204772, T: 88, Avg. loss: 0.615908\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.203307, T: 132, Avg. loss: 0.616266\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.202101, T: 176, Avg. loss: 0.615656\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.201044, T: 220, Avg. loss: 0.615530\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.200176, T: 264, Avg. loss: 0.615375\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.304064, T: 45, Avg. loss: 0.627521\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.298814, T: 90, Avg. loss: 0.619868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.295600, T: 135, Avg. loss: 0.620697\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.293254, T: 180, Avg. loss: 0.620701\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.291435, T: 225, Avg. loss: 0.620615\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.289969, T: 270, Avg. loss: 0.620682\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 7, Bias: 0.288749, T: 315, Avg. loss: 0.620489\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.203481, T: 45, Avg. loss: 0.621701\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.198750, T: 90, Avg. loss: 0.623065\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.197090, T: 135, Avg. loss: 0.623331\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.195661, T: 180, Avg. loss: 0.623471\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.194577, T: 225, Avg. loss: 0.623814\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.193798, T: 270, Avg. loss: 0.623387\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.151374, T: 44, Avg. loss: 0.679583\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.151047, T: 88, Avg. loss: 0.686647\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.150889, T: 132, Avg. loss: 0.686359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.150747, T: 176, Avg. loss: 0.686484\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.150676, T: 220, Avg. loss: 0.686434\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.150583, T: 264, Avg. loss: 0.686466\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.154382, T: 45, Avg. loss: 0.685106\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.154106, T: 90, Avg. loss: 0.687745\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.153930, T: 135, Avg. loss: 0.687901\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.153795, T: 180, Avg. loss: 0.687872\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.153693, T: 225, Avg. loss: 0.687895\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.01, NNZs: 7, Bias: 0.153611, T: 270, Avg. loss: 0.687925\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153805, T: 45, Avg. loss: 0.677012\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153490, T: 90, Avg. loss: 0.686289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153381, T: 135, Avg. loss: 0.686316\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153293, T: 180, Avg. loss: 0.686243\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153226, T: 225, Avg. loss: 0.686169\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.153166, T: 270, Avg. loss: 0.686247\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088179, T: 44, Avg. loss: 0.691182\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088158, T: 88, Avg. loss: 0.693145\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088151, T: 132, Avg. loss: 0.693163\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088142, T: 176, Avg. loss: 0.693153\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088137, T: 220, Avg. loss: 0.693148\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088133, T: 264, Avg. loss: 0.693151\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088183, T: 45, Avg. loss: 0.690199\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088160, T: 90, Avg. loss: 0.694102\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088141, T: 135, Avg. loss: 0.694093\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088131, T: 180, Avg. loss: 0.694090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088125, T: 225, Avg. loss: 0.694097\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.088119, T: 270, Avg. loss: 0.694099\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089630, T: 45, Avg. loss: 0.693505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089609, T: 90, Avg. loss: 0.694284\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089603, T: 135, Avg. loss: 0.694291\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089594, T: 180, Avg. loss: 0.694294\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089588, T: 225, Avg. loss: 0.694289\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: 0.089582, T: 270, Avg. loss: 0.694293\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "-- Epoch 1\n",
      "Norm: 43.06, NNZs: 7, Bias: -5.285034, T: 67, Avg. loss: 0.034708\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.56, NNZs: 7, Bias: -5.283568, T: 134, Avg. loss: 0.000001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 42.07, NNZs: 7, Bias: -5.281678, T: 201, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 41.60, NNZs: 7, Bias: -5.279540, T: 268, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 41.13, NNZs: 7, Bias: -5.277268, T: 335, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 40.67, NNZs: 7, Bias: -5.274743, T: 402, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 40.23, NNZs: 7, Bias: -5.271812, T: 469, Avg. loss: 0.000003\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "{'alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>4.699094e-04</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.706960e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001329</td>\n",
       "      <td>4.704150e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001662</td>\n",
       "      <td>4.699672e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>7.018853e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>5.840039e-07</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001662</td>\n",
       "      <td>4.704714e-04</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>4.701340e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.701903e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004322</td>\n",
       "      <td>4.016696e-03</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.706960e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>9</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.560101</td>\n",
       "      <td>0.052439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.701903e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.001661  4.699094e-04         0.000333    4.706960e-04       1e-05   \n",
       "1       0.001329  4.704150e-04         0.000000    0.000000e+00      0.0001   \n",
       "2       0.001662  4.699672e-04         0.000000    0.000000e+00       0.001   \n",
       "3       0.000997  1.946680e-07         0.000998    7.018853e-07        0.01   \n",
       "4       0.000997  5.840039e-07         0.000997    2.973602e-07         0.1   \n",
       "5       0.001662  4.704714e-04         0.000332    4.701340e-04         0.5   \n",
       "6       0.000998  1.946680e-07         0.000000    0.000000e+00         0.8   \n",
       "7       0.001330  4.701903e-04         0.000000    0.000000e+00           1   \n",
       "8       0.004322  4.016696e-03         0.000333    4.706960e-04          10   \n",
       "9       0.001330  4.701903e-04         0.000000    0.000000e+00         100   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 1e-05}           1.000000           1.000000           1.000000   \n",
       "1  {'alpha': 0.0001}           1.000000           1.000000           1.000000   \n",
       "2   {'alpha': 0.001}           1.000000           1.000000           1.000000   \n",
       "3    {'alpha': 0.01}           1.000000           1.000000           1.000000   \n",
       "4     {'alpha': 0.1}           1.000000           1.000000           1.000000   \n",
       "5     {'alpha': 0.5}           1.000000           1.000000           1.000000   \n",
       "6     {'alpha': 0.8}           1.000000           1.000000           1.000000   \n",
       "7       {'alpha': 1}           1.000000           1.000000           1.000000   \n",
       "8      {'alpha': 10}           0.652174           0.545455           0.727273   \n",
       "9     {'alpha': 100}           0.521739           0.500000           0.500000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         1.000000        0.000000                1            1.000000   \n",
       "1         1.000000        0.000000                1            1.000000   \n",
       "2         1.000000        0.000000                1            1.000000   \n",
       "3         1.000000        0.000000                1            1.000000   \n",
       "4         1.000000        0.000000                1            1.000000   \n",
       "5         1.000000        0.000000                1            1.000000   \n",
       "6         1.000000        0.000000                1            1.000000   \n",
       "7         1.000000        0.000000                1            1.000000   \n",
       "8         0.641634        0.074600                9            0.613636   \n",
       "9         0.507246        0.010248               10            0.500000   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000            1.000000          1.000000         0.000000  \n",
       "1            1.000000            1.000000          1.000000         0.000000  \n",
       "2            1.000000            1.000000          1.000000         0.000000  \n",
       "3            1.000000            1.000000          1.000000         0.000000  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  \n",
       "6            1.000000            1.000000          1.000000         0.000000  \n",
       "7            1.000000            1.000000          1.000000         0.000000  \n",
       "8            0.488889            0.577778          0.560101         0.052439  \n",
       "9            0.488889            0.511111          0.500000         0.009072  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "model_lr = SGDClassifier(loss='log', penalty='l2', tol=1e-3,verbose=2)\n",
    "\n",
    "parameters = {'alpha':[0.00001, 0.0001,0.001, 0.01, 0.1,0.5,0.8, 1, 10,  100,  1000]}\n",
    "# alphas = [0.00001, 0.0001,0.001, 0.01, 0.1,0.5,0.8, 1, 10,  100,  1000]\n",
    "# log_alphas =[]\n",
    "\n",
    "# for a in tqdm(alphas):\n",
    "#     b = math.log(a)\n",
    "#     log_alphas.append(b)\n",
    "\n",
    "clf = GridSearchCV(model_lr, parameters, cv= 3, scoring='neg_log_loss',return_train_score=True,verbose=2)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "#converting the clf.cv_results to dataframe\n",
    "\n",
    "results = pd.DataFrame.from_dict(clf.cv_results_)\n",
    "\n",
    "print(clf.best_params_) \n",
    "train_auc= clf.cv_results_['mean_train_score']\n",
    "train_auc_std= clf.cv_results_['std_train_score']\n",
    "cv_auc = clf.cv_results_['mean_test_score'] \n",
    "cv_auc_std= clf.cv_results_['std_test_score']\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 10.12, NNZs: 7, Bias: 3.879502, T: 67, Avg. loss: 0.012080\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 9.64, NNZs: 7, Bias: 3.758121, T: 134, Avg. loss: 0.000201\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 9.23, NNZs: 7, Bias: 3.635210, T: 201, Avg. loss: 0.000218\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 8.87, NNZs: 7, Bias: 3.513161, T: 268, Avg. loss: 0.000231\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 8.54, NNZs: 7, Bias: 3.406470, T: 335, Avg. loss: 0.000212\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 8.25, NNZs: 7, Bias: 3.302179, T: 402, Avg. loss: 0.000218\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 7.99, NNZs: 7, Bias: 3.197669, T: 469, Avg. loss: 0.000232\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', verbose=2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SGDClassifier(alpha =0.0001,loss='log', penalty='l2', tol=1e-3,verbose=2)\n",
    "best_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.77860012, -3.50736516,  4.96011811,  1.49060731, -3.50736516,\n",
       "         1.9404062 ,  2.34182637]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        16\n",
      "           1       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.97        33\n",
      "   macro avg       0.97      0.97      0.97        33\n",
      "weighted avg       0.97      0.97      0.97        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_edited = X_train+0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 29.06, NNZs: 7, Bias: 1.261129, T: 67, Avg. loss: 0.078709\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 36.78, NNZs: 7, Bias: -7.566324, T: 134, Avg. loss: 0.058683\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 34.85, NNZs: 7, Bias: -7.145901, T: 201, Avg. loss: 0.000748\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 33.08, NNZs: 7, Bias: -6.942529, T: 268, Avg. loss: 0.000388\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 31.47, NNZs: 7, Bias: -6.787929, T: 335, Avg. loss: 0.000309\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 30.01, NNZs: 7, Bias: -6.670504, T: 402, Avg. loss: 0.000241\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 28.69, NNZs: 7, Bias: -6.537599, T: 469, Avg. loss: 0.000290\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 27.47, NNZs: 7, Bias: -6.443755, T: 536, Avg. loss: 0.000207\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 8 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(loss='log', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_edited = SGDClassifier(alpha =0.0001,loss='log', penalty='l2', tol=1e-3,verbose=2)\n",
    "best_model_edited.fit(X_train_edited,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.18409746, -9.536426  , 15.18306943,  9.10813592, -9.536426  ,\n",
       "        10.03144904,  7.40326672]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_edited.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_edited.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 score difference between two models is 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82.53551549 63.22138755 67.33125581 83.63433171 63.22138755 80.65677058\n",
      "  68.3676617 ]]\n",
      "(1, 7)\n",
      "(7,)\n",
      "(7, 1)\n"
     ]
    }
   ],
   "source": [
    "#As there are collinear features were there,even after adding a slight noise ,weight vectors drastically changed.\n",
    "\n",
    "Weight_Vector_Difference = abs(100*((best_model_edited.coef_- best_model.coef_)/(best_model_edited.coef_)))\n",
    "print(Weight_Vector_Difference)\n",
    "print(Weight_Vector_Difference.shape)\n",
    "Weight_Vector_Difference_f = Weight_Vector_Difference.flatten()\n",
    "print(Weight_Vector_Difference_f.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 0 5 6]\n",
      "Index(['x*x', 'x', '2*z+3*x*x', 'w'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "indices = np.argsort(Weight_Vector_Difference_f)[::-1][0:4]\n",
    "print(indices)\n",
    "print(data.columns[indices])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 11 candidates, totalling 33 fits\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 68.72, NNZs: 7, Bias: 17.650794, T: 44, Avg. loss: 0.698630\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 68.19, NNZs: 7, Bias: 17.650794, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 67.67, NNZs: 7, Bias: 17.650794, T: 132, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 67.16, NNZs: 7, Bias: 17.650794, T: 176, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 66.65, NNZs: 7, Bias: 17.650794, T: 220, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 66.15, NNZs: 7, Bias: 17.650794, T: 264, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 65.66, NNZs: 7, Bias: 17.650794, T: 308, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 47.82, NNZs: 7, Bias: -17.782794, T: 45, Avg. loss: 0.022222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 47.44, NNZs: 7, Bias: -17.782794, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 47.07, NNZs: 7, Bias: -17.782794, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 46.70, NNZs: 7, Bias: -17.782794, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 46.34, NNZs: 7, Bias: -17.782794, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 45.99, NNZs: 7, Bias: -17.782794, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 45.64, NNZs: 7, Bias: -17.782794, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=1e-05 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 49.13, NNZs: 7, Bias: -0.034717, T: 45, Avg. loss: 0.290281\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 67.09, NNZs: 7, Bias: -17.657685, T: 90, Avg. loss: 0.390094\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 66.56, NNZs: 7, Bias: -17.657685, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 66.05, NNZs: 7, Bias: -17.657685, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 65.54, NNZs: 7, Bias: -17.657685, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 65.04, NNZs: 7, Bias: -17.657685, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 64.55, NNZs: 7, Bias: -17.657685, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 64.06, NNZs: 7, Bias: -17.657685, T: 360, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=1e-05, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 44.42, NNZs: 7, Bias: 10.058470, T: 44, Avg. loss: 0.276093\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 42.62, NNZs: 7, Bias: 10.058470, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 40.97, NNZs: 7, Bias: 10.058470, T: 132, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 39.43, NNZs: 7, Bias: 10.058470, T: 176, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 38.01, NNZs: 7, Bias: 10.058470, T: 220, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 36.68, NNZs: 7, Bias: 10.058470, T: 264, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 35.45, NNZs: 7, Bias: 10.058470, T: 308, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 21.38, NNZs: 7, Bias: 10.000000, T: 45, Avg. loss: 0.022222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.50, NNZs: 7, Bias: 10.000000, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 19.69, NNZs: 7, Bias: 10.000000, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 18.93, NNZs: 7, Bias: 10.000000, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 18.24, NNZs: 7, Bias: 10.000000, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 17.59, NNZs: 7, Bias: 10.000000, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 16.99, NNZs: 7, Bias: 10.000000, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.0001 ....................................................\n",
      "-- Epoch 1\n",
      "Norm: 32.66, NNZs: 5, Bias: 0.099010, T: 45, Avg. loss: 0.031076\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 31.31, NNZs: 5, Bias: 0.099010, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 30.07, NNZs: 5, Bias: 0.099010, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 28.92, NNZs: 5, Bias: 0.099010, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 27.86, NNZs: 5, Bias: 0.099010, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 26.87, NNZs: 5, Bias: 0.099010, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 25.95, NNZs: 5, Bias: 0.099010, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ..................................... alpha=0.0001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 21.33, NNZs: 7, Bias: 5.874636, T: 44, Avg. loss: 0.124064\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 17.79, NNZs: 7, Bias: 5.874636, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 15.25, NNZs: 7, Bias: 5.874636, T: 132, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 13.35, NNZs: 7, Bias: 5.874636, T: 176, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 11.87, NNZs: 7, Bias: 5.874636, T: 220, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 10.68, NNZs: 7, Bias: 5.874636, T: 264, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 9.71, NNZs: 7, Bias: 5.874636, T: 308, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 10.57, NNZs: 7, Bias: 0.717315, T: 45, Avg. loss: 0.036067\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 8.79, NNZs: 7, Bias: 0.717315, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 7.52, NNZs: 7, Bias: 0.717315, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 6.57, NNZs: 7, Bias: 0.717315, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 5.84, NNZs: 7, Bias: 0.717315, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 5.25, NNZs: 7, Bias: 0.717315, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 4.77, NNZs: 7, Bias: 0.717315, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.001 .....................................................\n",
      "-- Epoch 1\n",
      "Norm: 24.39, NNZs: 7, Bias: 0.620754, T: 45, Avg. loss: 0.084281\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 20.28, NNZs: 7, Bias: 0.620754, T: 90, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 17.35, NNZs: 7, Bias: 0.620754, T: 135, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 15.16, NNZs: 7, Bias: 0.620754, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 13.46, NNZs: 7, Bias: 0.620754, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.11, NNZs: 7, Bias: 0.620754, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 11.00, NNZs: 7, Bias: 0.620754, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ...................................... alpha=0.001, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 4.76, NNZs: 7, Bias: 1.105628, T: 44, Avg. loss: 0.065425\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.00, NNZs: 7, Bias: 1.105628, T: 88, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.84, NNZs: 7, Bias: 0.471202, T: 132, Avg. loss: 0.007967\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.23, NNZs: 7, Bias: 0.471202, T: 176, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.84, NNZs: 7, Bias: 0.471202, T: 220, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.57, NNZs: 7, Bias: 0.471202, T: 264, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.36, NNZs: 7, Bias: 0.471202, T: 308, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 4.12, NNZs: 7, Bias: 3.162278, T: 45, Avg. loss: 0.022222\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3.29, NNZs: 7, Bias: 2.127325, T: 90, Avg. loss: 0.045965\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 3.07, NNZs: 7, Bias: 1.405943, T: 135, Avg. loss: 0.004056\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.42, NNZs: 7, Bias: 1.405943, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.99, NNZs: 7, Bias: 1.405943, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 2.15, NNZs: 7, Bias: 1.064206, T: 270, Avg. loss: 0.001403\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.87, NNZs: 7, Bias: 1.064206, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.97, NNZs: 7, Bias: 0.808204, T: 360, Avg. loss: 0.002075\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.77, NNZs: 7, Bias: 0.808204, T: 405, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 3.55, NNZs: 7, Bias: -0.431736, T: 45, Avg. loss: 0.051358\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 2.92, NNZs: 7, Bias: 0.764110, T: 90, Avg. loss: 0.000161\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 2.71, NNZs: 7, Bias: 0.062960, T: 135, Avg. loss: 0.003358\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 2.13, NNZs: 7, Bias: 0.062960, T: 180, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.76, NNZs: 7, Bias: 0.062960, T: 225, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.49, NNZs: 7, Bias: 0.062960, T: 270, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.55, NNZs: 7, Bias: 0.353976, T: 315, Avg. loss: 0.002090\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=0.01, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 2.07, NNZs: 7, Bias: 1.673506, T: 44, Avg. loss: 0.185158\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.45, NNZs: 7, Bias: 1.202003, T: 88, Avg. loss: 0.050001\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.36, NNZs: 7, Bias: 0.834559, T: 132, Avg. loss: 0.030809\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.31, NNZs: 7, Bias: 0.587231, T: 176, Avg. loss: 0.015942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.10, NNZs: 7, Bias: 0.541068, T: 220, Avg. loss: 0.007707\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.07, NNZs: 7, Bias: 0.417508, T: 264, Avg. loss: 0.010124\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 7, Bias: 0.344700, T: 308, Avg. loss: 0.008016\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.99, NNZs: 7, Bias: 0.286537, T: 352, Avg. loss: 0.008683\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.00, NNZs: 7, Bias: 0.234989, T: 396, Avg. loss: 0.008219\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.97, NNZs: 7, Bias: 0.211906, T: 440, Avg. loss: 0.005057\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.96, NNZs: 7, Bias: 0.212488, T: 484, Avg. loss: 0.007951\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.98, NNZs: 7, Bias: 0.194096, T: 528, Avg. loss: 0.007427\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.98, NNZs: 7, Bias: 0.192956, T: 572, Avg. loss: 0.005920\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.96, NNZs: 7, Bias: 0.175174, T: 616, Avg. loss: 0.005599\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.95, NNZs: 7, Bias: 0.174592, T: 660, Avg. loss: 0.006099\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 1.94, NNZs: 7, Bias: 1.829294, T: 45, Avg. loss: 0.104090\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 1.65, NNZs: 7, Bias: 1.258405, T: 90, Avg. loss: 0.028426\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.30, NNZs: 7, Bias: 1.069164, T: 135, Avg. loss: 0.010721\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.21, NNZs: 7, Bias: 0.875579, T: 180, Avg. loss: 0.019027\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.09, NNZs: 7, Bias: 0.777829, T: 225, Avg. loss: 0.016752\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.12, NNZs: 7, Bias: 0.620773, T: 270, Avg. loss: 0.015518\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.04, NNZs: 7, Bias: 0.550778, T: 315, Avg. loss: 0.007788\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.99, NNZs: 7, Bias: 0.491800, T: 360, Avg. loss: 0.009816\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.96, NNZs: 7, Bias: 0.464829, T: 405, Avg. loss: 0.010096\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.97, NNZs: 7, Bias: 0.417180, T: 450, Avg. loss: 0.008405\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.94, NNZs: 7, Bias: 0.375817, T: 495, Avg. loss: 0.007706\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.92, NNZs: 7, Bias: 0.356082, T: 540, Avg. loss: 0.007426\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 12 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 1.42, NNZs: 7, Bias: 0.379057, T: 45, Avg. loss: 0.078465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.97, NNZs: 7, Bias: 0.318149, T: 90, Avg. loss: 0.004150\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1.04, NNZs: 7, Bias: 0.219060, T: 135, Avg. loss: 0.018916\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.00, NNZs: 7, Bias: 0.222829, T: 180, Avg. loss: 0.013044\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.06, NNZs: 7, Bias: 0.179082, T: 225, Avg. loss: 0.003505\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.02, NNZs: 7, Bias: 0.256661, T: 270, Avg. loss: 0.004070\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.97, NNZs: 7, Bias: 0.224607, T: 315, Avg. loss: 0.008921\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.1, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.75, NNZs: 7, Bias: 0.068813, T: 44, Avg. loss: 0.125536\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.69, NNZs: 7, Bias: 0.072062, T: 88, Avg. loss: 0.043121\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.060790, T: 132, Avg. loss: 0.059759\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.049942, T: 176, Avg. loss: 0.051355\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.067935, T: 220, Avg. loss: 0.058789\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.051632, T: 264, Avg. loss: 0.057385\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.057750, T: 308, Avg. loss: 0.057054\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.86, NNZs: 7, Bias: 0.176260, T: 45, Avg. loss: 0.089305\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.174955, T: 90, Avg. loss: 0.038621\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.144195, T: 135, Avg. loss: 0.044663\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.137434, T: 180, Avg. loss: 0.045091\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.129862, T: 225, Avg. loss: 0.041865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.123925, T: 270, Avg. loss: 0.043034\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.130701, T: 315, Avg. loss: 0.047424\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.74, NNZs: 7, Bias: 0.135127, T: 45, Avg. loss: 0.115209\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.71, NNZs: 7, Bias: 0.114231, T: 90, Avg. loss: 0.071594\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.70, NNZs: 7, Bias: 0.070205, T: 135, Avg. loss: 0.070721\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.070760, T: 180, Avg. loss: 0.071200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.69, NNZs: 7, Bias: 0.054468, T: 225, Avg. loss: 0.069138\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.69, NNZs: 7, Bias: 0.047184, T: 270, Avg. loss: 0.064704\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.043235, T: 315, Avg. loss: 0.067501\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.044312, T: 360, Avg. loss: 0.065157\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.044723, T: 405, Avg. loss: 0.065173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.039507, T: 450, Avg. loss: 0.064613\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.68, NNZs: 7, Bias: 0.044042, T: 495, Avg. loss: 0.064020\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 11 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.5, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.245611, T: 44, Avg. loss: 0.123875\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.170834, T: 88, Avg. loss: 0.084835\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.126388, T: 132, Avg. loss: 0.085127\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.113821, T: 176, Avg. loss: 0.071486\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.087396, T: 220, Avg. loss: 0.078016\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.077576, T: 264, Avg. loss: 0.083127\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.073000, T: 308, Avg. loss: 0.078190\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.060495, T: 352, Avg. loss: 0.079495\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.054480, T: 396, Avg. loss: 0.076065\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 9 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.71, NNZs: 7, Bias: 0.272179, T: 45, Avg. loss: 0.131257\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.200543, T: 90, Avg. loss: 0.061341\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.173245, T: 135, Avg. loss: 0.063917\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.162004, T: 180, Avg. loss: 0.065765\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.141785, T: 225, Avg. loss: 0.066768\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.136628, T: 270, Avg. loss: 0.066377\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.133487, T: 315, Avg. loss: 0.068085\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=0.8 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.64, NNZs: 7, Bias: -0.001882, T: 45, Avg. loss: 0.174055\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.050772, T: 90, Avg. loss: 0.098892\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.057134, T: 135, Avg. loss: 0.080050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.079969, T: 180, Avg. loss: 0.093299\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.073527, T: 225, Avg. loss: 0.087369\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.082776, T: 270, Avg. loss: 0.090737\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.087521, T: 315, Avg. loss: 0.087031\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.093650, T: 360, Avg. loss: 0.088470\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 8 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=0.8, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.000716, T: 44, Avg. loss: 0.206123\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.000707, T: 88, Avg. loss: 0.107269\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.58, NNZs: 7, Bias: -0.001827, T: 132, Avg. loss: 0.097967\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.000863, T: 176, Avg. loss: 0.099627\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.008286, T: 220, Avg. loss: 0.097735\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.004734, T: 264, Avg. loss: 0.096606\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.58, NNZs: 7, Bias: -0.001185, T: 308, Avg. loss: 0.098254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.001443, T: 352, Avg. loss: 0.099345\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.58, NNZs: 7, Bias: -0.003920, T: 396, Avg. loss: 0.098177\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.57, NNZs: 7, Bias: -0.001469, T: 440, Avg. loss: 0.091366\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.000499, T: 484, Avg. loss: 0.096583\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.004287, T: 528, Avg. loss: 0.095453\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.004127, T: 572, Avg. loss: 0.094868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.005413, T: 616, Avg. loss: 0.094594\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.003792, T: 660, Avg. loss: 0.093575\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.61, NNZs: 7, Bias: -0.146486, T: 45, Avg. loss: 0.210750\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.59, NNZs: 7, Bias: -0.035314, T: 90, Avg. loss: 0.098913\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.008984, T: 135, Avg. loss: 0.089787\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.015425, T: 180, Avg. loss: 0.090780\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.024988, T: 225, Avg. loss: 0.090173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.036054, T: 270, Avg. loss: 0.086135\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.039875, T: 315, Avg. loss: 0.090059\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.048968, T: 360, Avg. loss: 0.085515\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.051872, T: 405, Avg. loss: 0.085556\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.056623, T: 450, Avg. loss: 0.082287\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.058809, T: 495, Avg. loss: 0.083425\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.063088, T: 540, Avg. loss: 0.079698\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.066418, T: 585, Avg. loss: 0.081783\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.068325, T: 630, Avg. loss: 0.079835\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.071223, T: 675, Avg. loss: 0.079776\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.074198, T: 720, Avg. loss: 0.077891\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.076789, T: 765, Avg. loss: 0.080652\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.078126, T: 810, Avg. loss: 0.078545\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.076998, T: 855, Avg. loss: 0.078391\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.079230, T: 900, Avg. loss: 0.077940\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.080297, T: 945, Avg. loss: 0.078328\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 21 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=1 .........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.005206, T: 45, Avg. loss: 0.191970\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.057973, T: 90, Avg. loss: 0.105896\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.081243, T: 135, Avg. loss: 0.111780\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.094506, T: 180, Avg. loss: 0.105529\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.100761, T: 225, Avg. loss: 0.109528\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.104546, T: 270, Avg. loss: 0.109763\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.111918, T: 315, Avg. loss: 0.104224\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.118233, T: 360, Avg. loss: 0.105839\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.120961, T: 405, Avg. loss: 0.106010\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.125091, T: 450, Avg. loss: 0.103168\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.123255, T: 495, Avg. loss: 0.102430\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.121225, T: 540, Avg. loss: 0.102820\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.121438, T: 585, Avg. loss: 0.102160\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.119889, T: 630, Avg. loss: 0.102307\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.121440, T: 675, Avg. loss: 0.105542\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 15 epochs took 0.00 seconds\n",
      "[CV] .......................................... alpha=1, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.468816, T: 44, Avg. loss: 0.715325\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.459388, T: 88, Avg. loss: 0.690457\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.456490, T: 132, Avg. loss: 0.690322\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.453399, T: 176, Avg. loss: 0.686507\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.451322, T: 220, Avg. loss: 0.684148\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.449734, T: 264, Avg. loss: 0.684915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.448101, T: 308, Avg. loss: 0.682993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.446989, T: 352, Avg. loss: 0.682985\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.445949, T: 396, Avg. loss: 0.683400\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.444986, T: 440, Avg. loss: 0.683566\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.444127, T: 484, Avg. loss: 0.683458\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.443301, T: 528, Avg. loss: 0.681969\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.442594, T: 572, Avg. loss: 0.682997\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.441905, T: 616, Avg. loss: 0.682962\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.441272, T: 660, Avg. loss: 0.682442\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.440828, T: 704, Avg. loss: 0.682020\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.16, NNZs: 7, Bias: 0.440419, T: 748, Avg. loss: 0.681541\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 17 epochs took 0.00 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 7, Bias: -0.546419, T: 45, Avg. loss: 0.636776\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.544674, T: 90, Avg. loss: 0.609465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.542831, T: 135, Avg. loss: 0.611911\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.541962, T: 180, Avg. loss: 0.614989\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.541444, T: 225, Avg. loss: 0.613621\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.541008, T: 270, Avg. loss: 0.613329\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.540596, T: 315, Avg. loss: 0.611188\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 7 epochs took 0.02 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=10 ........................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.570783, T: 45, Avg. loss: 0.720823\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.567993, T: 90, Avg. loss: 0.680173\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.566423, T: 135, Avg. loss: 0.681510\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.565306, T: 180, Avg. loss: 0.681903\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.565074, T: 225, Avg. loss: 0.680632\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.564679, T: 270, Avg. loss: 0.679390\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.564279, T: 315, Avg. loss: 0.679308\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "[CV] ......................................... alpha=10, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326254, T: 44, Avg. loss: 0.940280\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326315, T: 88, Avg. loss: 0.961693\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326307, T: 132, Avg. loss: 0.961371\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326286, T: 176, Avg. loss: 0.961903\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326267, T: 220, Avg. loss: 0.961568\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.326231, T: 264, Avg. loss: 0.961601\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322757, T: 45, Avg. loss: 0.965198\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322379, T: 90, Avg. loss: 0.968518\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322253, T: 135, Avg. loss: 0.967516\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322180, T: 180, Avg. loss: 0.967585\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322126, T: 225, Avg. loss: 0.967482\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 7, Bias: 0.322079, T: 270, Avg. loss: 0.967459\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=100 .......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327239, T: 45, Avg. loss: 0.953616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327371, T: 90, Avg. loss: 0.958787\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327534, T: 135, Avg. loss: 0.959068\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327561, T: 180, Avg. loss: 0.958861\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327617, T: 225, Avg. loss: 0.959085\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.02, NNZs: 7, Bias: -0.327673, T: 270, Avg. loss: 0.959033\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ........................................ alpha=100, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177631, T: 44, Avg. loss: 0.981884\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177636, T: 88, Avg. loss: 0.996159\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177642, T: 132, Avg. loss: 0.996191\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177653, T: 176, Avg. loss: 0.996127\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177653, T: 220, Avg. loss: 0.996138\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.177653, T: 264, Avg. loss: 0.996159\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178939, T: 45, Avg. loss: 0.981077\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178968, T: 90, Avg. loss: 0.991927\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178979, T: 135, Avg. loss: 0.992008\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178982, T: 180, Avg. loss: 0.992023\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178985, T: 225, Avg. loss: 0.992019\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178991, T: 270, Avg. loss: 0.992010\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "[CV] alpha=1000 ......................................................\n",
      "-- Epoch 1\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178582, T: 45, Avg. loss: 0.983228\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178632, T: 90, Avg. loss: 0.992582\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178625, T: 135, Avg. loss: 0.992646\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178635, T: 180, Avg. loss: 0.992619\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178636, T: 225, Avg. loss: 0.992669\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.00, NNZs: 7, Bias: -0.178640, T: 270, Avg. loss: 0.992659\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "[CV] ....................................... alpha=1000, total=   0.0s\n",
      "-- Epoch 1\n",
      "Norm: 49.35, NNZs: 7, Bias: 35.540326, T: 67, Avg. loss: 0.022819\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 48.77, NNZs: 7, Bias: 35.540326, T: 134, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 48.21, NNZs: 7, Bias: 35.540326, T: 201, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 47.66, NNZs: 7, Bias: 35.540326, T: 268, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 47.13, NNZs: 7, Bias: 35.540326, T: 335, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 46.60, NNZs: 7, Bias: 35.540326, T: 402, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 46.09, NNZs: 7, Bias: 35.540326, T: 469, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n",
      "{'alpha': 1e-05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>4.699094e-04</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.706960e-04</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>{'alpha': 1e-05}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001329</td>\n",
       "      <td>4.704150e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001662</td>\n",
       "      <td>4.699672e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>7.018853e-07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000997</td>\n",
       "      <td>5.840039e-07</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>2.973602e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001662</td>\n",
       "      <td>4.704714e-04</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>4.701340e-04</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.946680e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>{'alpha': 0.8}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.701903e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1</td>\n",
       "      <td>{'alpha': 1}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004322</td>\n",
       "      <td>4.016696e-03</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>4.706960e-04</td>\n",
       "      <td>10</td>\n",
       "      <td>{'alpha': 10}</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.641634</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>9</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.560101</td>\n",
       "      <td>0.052439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001330</td>\n",
       "      <td>4.701903e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>100</td>\n",
       "      <td>{'alpha': 100}</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>10</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.009072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.001661  4.699094e-04         0.000333    4.706960e-04       1e-05   \n",
       "1       0.001329  4.704150e-04         0.000000    0.000000e+00      0.0001   \n",
       "2       0.001662  4.699672e-04         0.000000    0.000000e+00       0.001   \n",
       "3       0.000997  1.946680e-07         0.000998    7.018853e-07        0.01   \n",
       "4       0.000997  5.840039e-07         0.000997    2.973602e-07         0.1   \n",
       "5       0.001662  4.704714e-04         0.000332    4.701340e-04         0.5   \n",
       "6       0.000998  1.946680e-07         0.000000    0.000000e+00         0.8   \n",
       "7       0.001330  4.701903e-04         0.000000    0.000000e+00           1   \n",
       "8       0.004322  4.016696e-03         0.000333    4.706960e-04          10   \n",
       "9       0.001330  4.701903e-04         0.000000    0.000000e+00         100   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0   {'alpha': 1e-05}           1.000000           1.000000           1.000000   \n",
       "1  {'alpha': 0.0001}           1.000000           1.000000           1.000000   \n",
       "2   {'alpha': 0.001}           1.000000           1.000000           1.000000   \n",
       "3    {'alpha': 0.01}           1.000000           1.000000           1.000000   \n",
       "4     {'alpha': 0.1}           1.000000           1.000000           1.000000   \n",
       "5     {'alpha': 0.5}           1.000000           1.000000           1.000000   \n",
       "6     {'alpha': 0.8}           1.000000           1.000000           1.000000   \n",
       "7       {'alpha': 1}           1.000000           1.000000           1.000000   \n",
       "8      {'alpha': 10}           0.652174           0.545455           0.727273   \n",
       "9     {'alpha': 100}           0.521739           0.500000           0.500000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0         1.000000        0.000000                1            1.000000   \n",
       "1         1.000000        0.000000                1            1.000000   \n",
       "2         1.000000        0.000000                1            1.000000   \n",
       "3         1.000000        0.000000                1            1.000000   \n",
       "4         1.000000        0.000000                1            1.000000   \n",
       "5         1.000000        0.000000                1            1.000000   \n",
       "6         1.000000        0.000000                1            1.000000   \n",
       "7         1.000000        0.000000                1            1.000000   \n",
       "8         0.641634        0.074600                9            0.613636   \n",
       "9         0.507246        0.010248               10            0.500000   \n",
       "\n",
       "   split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0            1.000000            1.000000          1.000000         0.000000  \n",
       "1            1.000000            1.000000          1.000000         0.000000  \n",
       "2            1.000000            1.000000          1.000000         0.000000  \n",
       "3            1.000000            1.000000          1.000000         0.000000  \n",
       "4            1.000000            1.000000          1.000000         0.000000  \n",
       "5            1.000000            1.000000          1.000000         0.000000  \n",
       "6            1.000000            1.000000          1.000000         0.000000  \n",
       "7            1.000000            1.000000          1.000000         0.000000  \n",
       "8            0.488889            0.577778          0.560101         0.052439  \n",
       "9            0.488889            0.511111          0.500000         0.009072  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import hinge_loss\n",
    "\n",
    "model_svm = SGDClassifier(loss='hinge',penalty='l2', tol=1e-3, verbose=2)\n",
    "\n",
    "parameters = {'alpha':[0.00001, 0.0001,0.001, 0.01, 0.1,0.5,0.8, 1, 10,  100,  1000]}\n",
    "# alphas = [0.00001, 0.0001,0.001, 0.01, 0.1,0.5,0.8, 1, 10,  100,  1000]\n",
    "# log_alphas =[]\n",
    "\n",
    "# for a in tqdm(alphas):\n",
    "#     b = math.log(a)\n",
    "#     log_alphas.append(b)\n",
    "\n",
    "clf_svm = GridSearchCV(model_svm, parameters, cv= 3, scoring='accuracy',return_train_score=True,verbose=2)\n",
    "\n",
    "clf_svm.fit(X_train,y_train)\n",
    "#converting the clf.cv_results to dataframe\n",
    "\n",
    "results_svm = pd.DataFrame.from_dict(clf_svm.cv_results_)\n",
    "\n",
    "print(clf_svm.best_params_) \n",
    "train_auc_svm= clf_svm.cv_results_['mean_train_score']\n",
    "train_auc_std_svm= clf_svm.cv_results_['std_train_score']\n",
    "cv_auc_svm = clf_svm.cv_results_['mean_test_score'] \n",
    "cv_auc_std_svm= clf_svm.cv_results_['std_test_score']\n",
    "results.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.000100, T: 67, Avg. loss: 0.987913\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 7, Bias: -0.000200, T: 134, Avg. loss: 0.962970\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.04, NNZs: 7, Bias: -0.000300, T: 201, Avg. loss: 0.938027\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 7, Bias: -0.000400, T: 268, Avg. loss: 0.913083\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 7, Bias: -0.000500, T: 335, Avg. loss: 0.888140\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.000600, T: 402, Avg. loss: 0.863197\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 7, Bias: -0.000700, T: 469, Avg. loss: 0.838254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.10, NNZs: 7, Bias: -0.000800, T: 536, Avg. loss: 0.813311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.12, NNZs: 7, Bias: -0.000900, T: 603, Avg. loss: 0.788368\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 7, Bias: -0.001000, T: 670, Avg. loss: 0.763424\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.14, NNZs: 7, Bias: -0.001100, T: 737, Avg. loss: 0.738481\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.16, NNZs: 7, Bias: -0.001200, T: 804, Avg. loss: 0.713538\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.001300, T: 871, Avg. loss: 0.688595\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.18, NNZs: 7, Bias: -0.001400, T: 938, Avg. loss: 0.663652\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.001500, T: 1005, Avg. loss: 0.638709\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 7, Bias: -0.001600, T: 1072, Avg. loss: 0.613766\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 7, Bias: -0.001700, T: 1139, Avg. loss: 0.588823\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 7, Bias: -0.001800, T: 1206, Avg. loss: 0.563879\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.25, NNZs: 7, Bias: -0.001900, T: 1273, Avg. loss: 0.538936\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.26, NNZs: 7, Bias: -0.002000, T: 1340, Avg. loss: 0.513993\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.27, NNZs: 7, Bias: -0.002100, T: 1407, Avg. loss: 0.489050\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.28, NNZs: 7, Bias: -0.002300, T: 1474, Avg. loss: 0.464706\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.30, NNZs: 7, Bias: -0.002700, T: 1541, Avg. loss: 0.443087\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.31, NNZs: 7, Bias: -0.003200, T: 1608, Avg. loss: 0.423616\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.32, NNZs: 7, Bias: -0.003700, T: 1675, Avg. loss: 0.406025\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.33, NNZs: 7, Bias: -0.004300, T: 1742, Avg. loss: 0.388789\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.34, NNZs: 7, Bias: -0.004900, T: 1809, Avg. loss: 0.372150\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.35, NNZs: 7, Bias: -0.005500, T: 1876, Avg. loss: 0.355511\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.36, NNZs: 7, Bias: -0.006200, T: 1943, Avg. loss: 0.339441\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.37, NNZs: 7, Bias: -0.006900, T: 2010, Avg. loss: 0.323677\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.38, NNZs: 7, Bias: -0.007600, T: 2077, Avg. loss: 0.307914\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.39, NNZs: 7, Bias: -0.008300, T: 2144, Avg. loss: 0.292151\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.40, NNZs: 7, Bias: -0.008900, T: 2211, Avg. loss: 0.277046\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.41, NNZs: 7, Bias: -0.009200, T: 2278, Avg. loss: 0.264819\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.42, NNZs: 7, Bias: -0.009500, T: 2345, Avg. loss: 0.253371\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.43, NNZs: 7, Bias: -0.009700, T: 2412, Avg. loss: 0.242133\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.43, NNZs: 7, Bias: -0.009600, T: 2479, Avg. loss: 0.232316\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.44, NNZs: 7, Bias: -0.009600, T: 2546, Avg. loss: 0.223534\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.45, NNZs: 7, Bias: -0.009600, T: 2613, Avg. loss: 0.214943\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.46, NNZs: 7, Bias: -0.009400, T: 2680, Avg. loss: 0.206865\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.46, NNZs: 7, Bias: -0.009100, T: 2747, Avg. loss: 0.199524\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.47, NNZs: 7, Bias: -0.008800, T: 2814, Avg. loss: 0.192331\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.48, NNZs: 7, Bias: -0.008400, T: 2881, Avg. loss: 0.185383\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.48, NNZs: 7, Bias: -0.008000, T: 2948, Avg. loss: 0.178615\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.007600, T: 3015, Avg. loss: 0.171846\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.007200, T: 3082, Avg. loss: 0.165078\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.006600, T: 3149, Avg. loss: 0.159221\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.51, NNZs: 7, Bias: -0.006000, T: 3216, Avg. loss: 0.153868\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.51, NNZs: 7, Bias: -0.005400, T: 3283, Avg. loss: 0.148908\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.52, NNZs: 7, Bias: -0.004800, T: 3350, Avg. loss: 0.144210\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.52, NNZs: 7, Bias: -0.003900, T: 3417, Avg. loss: 0.139912\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.53, NNZs: 7, Bias: -0.003200, T: 3484, Avg. loss: 0.136311\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.53, NNZs: 7, Bias: -0.002500, T: 3551, Avg. loss: 0.133031\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.54, NNZs: 7, Bias: -0.001900, T: 3618, Avg. loss: 0.129895\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.54, NNZs: 7, Bias: -0.001300, T: 3685, Avg. loss: 0.126879\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.55, NNZs: 7, Bias: -0.000600, T: 3752, Avg. loss: 0.123975\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.55, NNZs: 7, Bias: 0.000100, T: 3819, Avg. loss: 0.121251\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.55, NNZs: 7, Bias: 0.000800, T: 3886, Avg. loss: 0.118830\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.001500, T: 3953, Avg. loss: 0.116409\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.002100, T: 4020, Avg. loss: 0.114097\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.002700, T: 4087, Avg. loss: 0.111884\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.003300, T: 4154, Avg. loss: 0.109670\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.004000, T: 4221, Avg. loss: 0.107646\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.004700, T: 4288, Avg. loss: 0.105644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.005400, T: 4355, Avg. loss: 0.103641\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.006100, T: 4422, Avg. loss: 0.101763\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.006800, T: 4489, Avg. loss: 0.100079\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.007500, T: 4556, Avg. loss: 0.098395\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.008200, T: 4623, Avg. loss: 0.096711\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.008900, T: 4690, Avg. loss: 0.095027\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.009600, T: 4757, Avg. loss: 0.093342\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.010300, T: 4824, Avg. loss: 0.091658\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.010900, T: 4891, Avg. loss: 0.090109\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.011500, T: 4958, Avg. loss: 0.088619\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.012100, T: 5025, Avg. loss: 0.087129\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.012700, T: 5092, Avg. loss: 0.085639\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.013300, T: 5159, Avg. loss: 0.084149\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.013900, T: 5226, Avg. loss: 0.082660\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.014500, T: 5293, Avg. loss: 0.081170\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.015200, T: 5360, Avg. loss: 0.079718\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.015800, T: 5427, Avg. loss: 0.078305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.016400, T: 5494, Avg. loss: 0.077064\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.017000, T: 5561, Avg. loss: 0.075823\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.017600, T: 5628, Avg. loss: 0.074582\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.018200, T: 5695, Avg. loss: 0.073341\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.018800, T: 5762, Avg. loss: 0.072100\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.019500, T: 5829, Avg. loss: 0.070891\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.020200, T: 5896, Avg. loss: 0.069757\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.020900, T: 5963, Avg. loss: 0.068623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.021600, T: 6030, Avg. loss: 0.067488\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.022200, T: 6097, Avg. loss: 0.066372\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.022900, T: 6164, Avg. loss: 0.065361\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.023500, T: 6231, Avg. loss: 0.064495\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.024100, T: 6298, Avg. loss: 0.063704\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.024700, T: 6365, Avg. loss: 0.062913\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.025300, T: 6432, Avg. loss: 0.062122\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.025900, T: 6499, Avg. loss: 0.061331\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 97 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, eta0=0.0001, learning_rate='constant', verbose=2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_svm = SGDClassifier(eta0=0.0001,alpha =0.00001,loss='hinge', penalty='l2', tol=1e-3,verbose=2,learning_rate='constant')\n",
    "best_model_svm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19546449, -0.27204053,  0.37084126,  0.18892426, -0.27204053,\n",
       "         0.21480606,  0.19181447]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_svm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_svm.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_edited_svm = X_train+0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.01, NNZs: 7, Bias: -0.000100, T: 67, Avg. loss: 0.987915\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.03, NNZs: 7, Bias: -0.000200, T: 134, Avg. loss: 0.962976\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.04, NNZs: 7, Bias: -0.000300, T: 201, Avg. loss: 0.938037\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.05, NNZs: 7, Bias: -0.000400, T: 268, Avg. loss: 0.913098\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.06, NNZs: 7, Bias: -0.000500, T: 335, Avg. loss: 0.888160\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.08, NNZs: 7, Bias: -0.000600, T: 402, Avg. loss: 0.863221\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.09, NNZs: 7, Bias: -0.000700, T: 469, Avg. loss: 0.838282\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.10, NNZs: 7, Bias: -0.000800, T: 536, Avg. loss: 0.813343\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.12, NNZs: 7, Bias: -0.000900, T: 603, Avg. loss: 0.788404\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.13, NNZs: 7, Bias: -0.001000, T: 670, Avg. loss: 0.763465\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.14, NNZs: 7, Bias: -0.001100, T: 737, Avg. loss: 0.738526\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 0.16, NNZs: 7, Bias: -0.001200, T: 804, Avg. loss: 0.713588\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 0.17, NNZs: 7, Bias: -0.001300, T: 871, Avg. loss: 0.688649\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 0.18, NNZs: 7, Bias: -0.001400, T: 938, Avg. loss: 0.663710\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 0.19, NNZs: 7, Bias: -0.001500, T: 1005, Avg. loss: 0.638771\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 0.21, NNZs: 7, Bias: -0.001600, T: 1072, Avg. loss: 0.613832\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 0.22, NNZs: 7, Bias: -0.001700, T: 1139, Avg. loss: 0.588893\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 0.23, NNZs: 7, Bias: -0.001800, T: 1206, Avg. loss: 0.563954\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 0.25, NNZs: 7, Bias: -0.001900, T: 1273, Avg. loss: 0.539016\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 0.26, NNZs: 7, Bias: -0.002000, T: 1340, Avg. loss: 0.514077\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 0.27, NNZs: 7, Bias: -0.002100, T: 1407, Avg. loss: 0.489138\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 0.28, NNZs: 7, Bias: -0.002400, T: 1474, Avg. loss: 0.465310\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 0.30, NNZs: 7, Bias: -0.002900, T: 1541, Avg. loss: 0.444254\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 0.31, NNZs: 7, Bias: -0.003500, T: 1608, Avg. loss: 0.424917\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 0.32, NNZs: 7, Bias: -0.004000, T: 1675, Avg. loss: 0.406932\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 0.33, NNZs: 7, Bias: -0.004600, T: 1742, Avg. loss: 0.389740\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 0.34, NNZs: 7, Bias: -0.005200, T: 1809, Avg. loss: 0.373119\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 0.35, NNZs: 7, Bias: -0.005900, T: 1876, Avg. loss: 0.356653\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 0.36, NNZs: 7, Bias: -0.006600, T: 1943, Avg. loss: 0.340910\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 0.37, NNZs: 7, Bias: -0.007300, T: 2010, Avg. loss: 0.325167\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 0.38, NNZs: 7, Bias: -0.008000, T: 2077, Avg. loss: 0.309425\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 0.39, NNZs: 7, Bias: -0.008700, T: 2144, Avg. loss: 0.293682\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 0.40, NNZs: 7, Bias: -0.009300, T: 2211, Avg. loss: 0.278561\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 0.41, NNZs: 7, Bias: -0.009600, T: 2278, Avg. loss: 0.265966\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 0.42, NNZs: 7, Bias: -0.009900, T: 2345, Avg. loss: 0.254526\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 0.42, NNZs: 7, Bias: -0.010200, T: 2412, Avg. loss: 0.243087\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 0.43, NNZs: 7, Bias: -0.010100, T: 2479, Avg. loss: 0.232864\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 0.44, NNZs: 7, Bias: -0.010100, T: 2546, Avg. loss: 0.224114\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 0.45, NNZs: 7, Bias: -0.010100, T: 2613, Avg. loss: 0.215523\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 0.45, NNZs: 7, Bias: -0.009900, T: 2680, Avg. loss: 0.207283\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 0.46, NNZs: 7, Bias: -0.009600, T: 2747, Avg. loss: 0.199846\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 0.47, NNZs: 7, Bias: -0.009300, T: 2814, Avg. loss: 0.192647\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 0.48, NNZs: 7, Bias: -0.008900, T: 2881, Avg. loss: 0.185623\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 0.48, NNZs: 7, Bias: -0.008500, T: 2948, Avg. loss: 0.178847\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 0.49, NNZs: 7, Bias: -0.008100, T: 3015, Avg. loss: 0.172070\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.007600, T: 3082, Avg. loss: 0.165346\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 0.50, NNZs: 7, Bias: -0.007100, T: 3149, Avg. loss: 0.159332\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 0.51, NNZs: 7, Bias: -0.006500, T: 3216, Avg. loss: 0.153815\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 0.51, NNZs: 7, Bias: -0.006000, T: 3283, Avg. loss: 0.148710\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 0.52, NNZs: 7, Bias: -0.005400, T: 3350, Avg. loss: 0.143958\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 0.52, NNZs: 7, Bias: -0.004800, T: 3417, Avg. loss: 0.139429\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 0.53, NNZs: 7, Bias: -0.004100, T: 3484, Avg. loss: 0.135806\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 0.53, NNZs: 7, Bias: -0.003400, T: 3551, Avg. loss: 0.132520\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 0.54, NNZs: 7, Bias: -0.002800, T: 3618, Avg. loss: 0.129442\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 0.54, NNZs: 7, Bias: -0.002200, T: 3685, Avg. loss: 0.126421\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 0.55, NNZs: 7, Bias: -0.001600, T: 3752, Avg. loss: 0.123401\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 0.55, NNZs: 7, Bias: -0.001000, T: 3819, Avg. loss: 0.120614\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 0.55, NNZs: 7, Bias: -0.000300, T: 3886, Avg. loss: 0.118104\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.000300, T: 3953, Avg. loss: 0.115758\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.000900, T: 4020, Avg. loss: 0.113541\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 0.56, NNZs: 7, Bias: 0.001500, T: 4087, Avg. loss: 0.111325\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.002200, T: 4154, Avg. loss: 0.109131\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 0.57, NNZs: 7, Bias: 0.002900, T: 4221, Avg. loss: 0.107125\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.003600, T: 4288, Avg. loss: 0.105118\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.004200, T: 4355, Avg. loss: 0.103161\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.004800, T: 4422, Avg. loss: 0.101340\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 0.58, NNZs: 7, Bias: 0.005500, T: 4489, Avg. loss: 0.099568\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.006200, T: 4556, Avg. loss: 0.097880\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.006900, T: 4623, Avg. loss: 0.096193\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 0.59, NNZs: 7, Bias: 0.007600, T: 4690, Avg. loss: 0.094506\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.008300, T: 4757, Avg. loss: 0.092819\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.008900, T: 4824, Avg. loss: 0.091236\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 0.60, NNZs: 7, Bias: 0.009500, T: 4891, Avg. loss: 0.089743\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.010100, T: 4958, Avg. loss: 0.088251\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.010700, T: 5025, Avg. loss: 0.086759\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 0.61, NNZs: 7, Bias: 0.011300, T: 5092, Avg. loss: 0.085266\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.011900, T: 5159, Avg. loss: 0.083774\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.012500, T: 5226, Avg. loss: 0.082281\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.013100, T: 5293, Avg. loss: 0.080789\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 0.62, NNZs: 7, Bias: 0.013700, T: 5360, Avg. loss: 0.079296\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.014300, T: 5427, Avg. loss: 0.077893\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.014900, T: 5494, Avg. loss: 0.076650\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.015500, T: 5561, Avg. loss: 0.075407\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 0.63, NNZs: 7, Bias: 0.016100, T: 5628, Avg. loss: 0.074164\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.016700, T: 5695, Avg. loss: 0.072921\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.017300, T: 5762, Avg. loss: 0.071678\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 0.64, NNZs: 7, Bias: 0.017900, T: 5829, Avg. loss: 0.070436\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.018600, T: 5896, Avg. loss: 0.069210\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.019300, T: 5963, Avg. loss: 0.068074\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.019900, T: 6030, Avg. loss: 0.066972\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 0.65, NNZs: 7, Bias: 0.020500, T: 6097, Avg. loss: 0.065951\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.021100, T: 6164, Avg. loss: 0.064930\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.021600, T: 6231, Avg. loss: 0.064044\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.022200, T: 6298, Avg. loss: 0.063212\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.022800, T: 6365, Avg. loss: 0.062420\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 0.66, NNZs: 7, Bias: 0.023400, T: 6432, Avg. loss: 0.061629\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 0.67, NNZs: 7, Bias: 0.024000, T: 6499, Avg. loss: 0.060837\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 97 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-05, eta0=0.0001, learning_rate='constant', verbose=2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_edited_svm = SGDClassifier(eta0=0.0001,alpha =0.00001,loss='hinge', penalty='l2', tol=1e-3,verbose=2,learning_rate='constant')\n",
    "best_model_edited_svm.fit(X_train_edited_svm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19593143, -0.2718675 ,  0.37134189,  0.1893914 , -0.2718675 ,\n",
       "         0.21528195,  0.19169079]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_edited_svm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           1.00        33\n",
      "   macro avg       1.00      1.00      1.00        33\n",
      "weighted avg       1.00      1.00      1.00        33\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_edited_svm.predict(X_test) \n",
    "   \n",
    "# print classification report \n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Difference is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23832067 0.06364541 0.13481605 0.24665102 0.06364541 0.22105457\n",
      "  0.06452142]]\n",
      "(1, 7)\n",
      "(7,)\n"
     ]
    }
   ],
   "source": [
    "#As there are collinear features were there,even after adding a slight noise ,weight vectors drastically changed.\n",
    "\n",
    "Weight_Vector_Difference_svm = abs(100*((best_model_edited_svm.coef_- best_model_svm.coef_)/(best_model_edited_svm.coef_)))\n",
    "print(Weight_Vector_Difference_svm)\n",
    "print(Weight_Vector_Difference_svm.shape)\n",
    "Weight_Vector_Difference_f_svm = Weight_Vector_Difference.flatten()\n",
    "print(Weight_Vector_Difference_f_svm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 2 4 1]\n",
      "Index(['w', 'z', '2*y', 'y'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "indices_svm = np.argsort(Weight_Vector_Difference_f_svm)[::-1][0:4]\n",
    "print(indices_svm)\n",
    "print(data.columns[indices_svm])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "8D_LR_SVM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
